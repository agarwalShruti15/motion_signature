2019-10-28 05:03:51,522 Train INFO: CODE_PATH: /data/home/shruti/voxceleb/motion_signature/research-ms-loss-master/
DATA:
  NUM_INSTANCES: 5
  NUM_WORKERS: 20
  TEST_BATCHSIZE: 20
  TEST_IMG_SOURCE: /data/home/shruti/voxceleb/aus/leaders/leaders_100_val.txt
  TRAIN_BATCHSIZE: 50
  TRAIN_IMG_SOURCE: /data/home/shruti/voxceleb/aus/leaders/leaders_100_train.txt
INPUT:
  DATA_LOADER: FabNet
  EVAL: accuracy
  FRAME_LENGTH: 100
  MEAN: /data/home/shruti/voxceleb/aus/leaders/leaders_300_mean.npy
  SAMPLER: random_identity_sampler
  STD: /data/home/shruti/voxceleb/aus/leaders/leaders_300_std.npy
  TRANSFORM: standard_scalar
LOGGER:
  LEVEL: 20
  STREAM: stdout
LOSSES:
  MULTI_SIMILARITY_LOSS:
    HARD_MINING: True
    SCALE_NEG: 40.0
    SCALE_POS: 2.0
  NAME: ce_loss
MODEL:
  BACKBONE:
    LR_MUL: 1.0
    NAME: asym_alexnet
  DEVICE: cuda
  HEAD:
    DIM: 10
    IN_CHANNEL: 1024
    LR_MUL: 1.0
    NAME: linear_norm
  PRETRAIN: none
  PRETRIANED_PATH: /data/home/shruti/voxceleb/
  WEIGHT: 
SAVE_DIR: /data/home/shruti/voxceleb/aus_ldrs_clss_T100_asymalexnet_iter600
SOLVER:
  BASE_LR: 3e-05
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 10000
  FINETURN_MODE_PATH: 
  GAMMA: 0.1
  IS_FINETURN: False
  MAX_ITERS: 600
  MOMENTUM: 0.9
  OPTIMIZER_NAME: Adam
  RNG_SEED: 1
  STEPS: [100000]
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0005
  WEIGHT_DECAY_BIAS: 0.0005
VALIDATION:
  IS_VALIDATION: True
  VERBOSE: 200
10
10
2019-10-28 05:04:00,337 Train INFO: | Dataset Info |datasize: 3289|num_labels: 10|
2019-10-28 05:04:00,337 Train INFO: | Dataset Info |datasize: 407|num_labels: 10|
2019-10-28 05:04:00,345 Train INFO: Start training
2019-10-28 05:04:02,022 Train INFO: Validation
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] [5 0 2 0 3 3 2 4 4 4 9 4 5 2 4 1 8 4 4 2]
2019-10-28 05:04:03,516 Train INFO: Best iteration 0: accuracy: 0.057
2019-10-28 05:04:05,749 Train INFO: eta: 0:02:36  iter: 20  time: 0.0271 (0.2698)  data: 0.0121 (0.2534)  loss: 2.3109 (2.3242)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:06,279 Train INFO: eta: 0:01:22  iter: 40  time: 0.0258 (0.1480)  data: 0.0092 (0.1313)  loss: 2.3044 (2.3140)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:06,808 Train INFO: eta: 0:00:58  iter: 60  time: 0.0265 (0.1075)  data: 0.0112 (0.0912)  loss: 2.3001 (2.3102)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:07,347 Train INFO: eta: 0:00:45  iter: 80  time: 0.0269 (0.0874)  data: 0.0110 (0.0712)  loss: 2.2966 (2.3066)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:07,874 Train INFO: eta: 0:00:37  iter: 100  time: 0.0254 (0.0752)  data: 0.0100 (0.0590)  loss: 2.2751 (2.2967)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:08,409 Train INFO: eta: 0:00:32  iter: 120  time: 0.0265 (0.0671)  data: 0.0110 (0.0509)  loss: 2.0996 (2.2649)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:08,945 Train INFO: eta: 0:00:28  iter: 140  time: 0.0262 (0.0613)  data: 0.0110 (0.0452)  loss: 2.0515 (2.2359)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:09,475 Train INFO: eta: 0:00:25  iter: 160  time: 0.0264 (0.0570)  data: 0.0108 (0.0409)  loss: 2.0460 (2.2121)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:10,006 Train INFO: eta: 0:00:22  iter: 180  time: 0.0260 (0.0536)  data: 0.0099 (0.0374)  loss: 2.0283 (2.1911)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:10,540 Train INFO: eta: 0:00:20  iter: 200  time: 0.0266 (0.0509)  data: 0.0099 (0.0347)  loss: 2.0061 (2.1731)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:10,540 Train INFO: Validation
[9 6 3 2 0 0 2 3 5 9 9 4 3 2 2 3 9 5 0 6] [8 1 3 4 0 0 4 3 4 7 0 4 0 7 2 3 9 2 3 6]
2019-10-28 05:04:12,029 Train INFO: Best iteration 200: accuracy: 0.381
2019-10-28 05:04:17,591 Train INFO: eta: 0:00:29  iter: 220  time: 0.0274 (0.0784)  data: 0.0124 (0.0623)  loss: 2.0069 (2.1580)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:18,118 Train INFO: eta: 0:00:26  iter: 240  time: 0.0260 (0.0740)  data: 0.0092 (0.0579)  loss: 1.9890 (2.1440)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:18,653 Train INFO: eta: 0:00:23  iter: 260  time: 0.0264 (0.0704)  data: 0.0101 (0.0542)  loss: 1.9664 (2.1304)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:19,185 Train INFO: eta: 0:00:21  iter: 280  time: 0.0265 (0.0672)  data: 0.0104 (0.0511)  loss: 1.9561 (2.1182)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:19,718 Train INFO: eta: 0:00:19  iter: 300  time: 0.0264 (0.0645)  data: 0.0111 (0.0484)  loss: 1.9558 (2.1076)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:20,256 Train INFO: eta: 0:00:17  iter: 320  time: 0.0267 (0.0622)  data: 0.0112 (0.0461)  loss: 1.9425 (2.0976)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:20,793 Train INFO: eta: 0:00:15  iter: 340  time: 0.0262 (0.0601)  data: 0.0088 (0.0439)  loss: 1.9448 (2.0881)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:21,327 Train INFO: eta: 0:00:13  iter: 360  time: 0.0266 (0.0583)  data: 0.0108 (0.0421)  loss: 1.9104 (2.0782)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:21,873 Train INFO: eta: 0:00:12  iter: 380  time: 0.0268 (0.0566)  data: 0.0105 (0.0404)  loss: 1.9225 (2.0698)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:22,409 Train INFO: eta: 0:00:11  iter: 400  time: 0.0263 (0.0551)  data: 0.0102 (0.0389)  loss: 1.8846 (2.0609)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:22,409 Train INFO: Validation
[0 2 1 2 4 0 0 9 2 9 7 2 4 0 3 2 2 3 8 4] [0 4 1 4 7 0 0 9 2 0 0 2 4 0 3 8 2 3 9 4]
2019-10-28 05:04:23,864 Train INFO: Best iteration 400: accuracy: 0.595
2019-10-28 05:04:29,988 Train INFO: eta: 0:00:12  iter: 420  time: 0.0258 (0.0706)  data: 0.0115 (0.0544)  loss: 1.8630 (2.0516)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:30,520 Train INFO: eta: 0:00:10  iter: 440  time: 0.0257 (0.0686)  data: 0.0104 (0.0524)  loss: 1.8583 (2.0430)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:31,059 Train INFO: eta: 0:00:09  iter: 460  time: 0.0269 (0.0667)  data: 0.0108 (0.0506)  loss: 1.8499 (2.0348)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:31,596 Train INFO: eta: 0:00:07  iter: 480  time: 0.0257 (0.0651)  data: 0.0101 (0.0489)  loss: 1.8400 (2.0265)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:32,130 Train INFO: eta: 0:00:06  iter: 500  time: 0.0268 (0.0635)  data: 0.0106 (0.0473)  loss: 1.8441 (2.0188)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:32,664 Train INFO: eta: 0:00:04  iter: 520  time: 0.0264 (0.0621)  data: 0.0100 (0.0459)  loss: 1.8187 (2.0111)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:33,189 Train INFO: eta: 0:00:03  iter: 540  time: 0.0265 (0.0608)  data: 0.0102 (0.0446)  loss: 1.7898 (2.0034)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:33,721 Train INFO: eta: 0:00:02  iter: 560  time: 0.0263 (0.0596)  data: 0.0106 (0.0434)  loss: 1.7934 (1.9961)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:34,246 Train INFO: eta: 0:00:01  iter: 580  time: 0.0256 (0.0584)  data: 0.0111 (0.0423)  loss: 1.7878 (1.9890)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:34,757 Train INFO: eta: 0:00:00  iter: 600  time: 0.0256 (0.0573)  data: 0.0120 (0.0413)  loss: 1.7780 (1.9818)  lr: 0.000030  max mem: 1.9 GB
2019-10-28 05:04:34,842 Train INFO: Total training time: 0:00:34.496987 (0.0575 s / it)
2019-10-28 05:04:34,842 Train INFO: Best iteration: 000400 | best recall 0.5945945945945946 
