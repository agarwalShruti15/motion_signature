2019-10-29 10:27:37,614 Train INFO: CODE_PATH: /data/home/shruti/voxceleb/motion_signature/research-ms-loss-master/
DATA:
  NUM_INSTANCES: 5
  NUM_WORKERS: 20
  TEST_BATCHSIZE: 20
  TEST_IMG_SOURCE: /data/home/shruti/voxceleb/fabnet/leaders/leaders_100_val.txt
  TRAIN_BATCHSIZE: 50
  TRAIN_IMG_SOURCE: /data/home/shruti/voxceleb/fabnet/leaders/leaders_100_train.txt
INPUT:
  DATA_LOADER: FabNet
  EVAL: accuracy
  FRAME_LENGTH: 100
  MEAN: /data/home/shruti/voxceleb/fabnet/leaders/leaders_300_mean.npy
  SAMPLER: random_identity_sampler
  STD: /data/home/shruti/voxceleb/fabnet/leaders/leaders_300_std.npy
  TRANSFORM: standard_scalar
LOGGER:
  LEVEL: 20
  STREAM: stdout
LOSSES:
  MULTI_SIMILARITY_LOSS:
    HARD_MINING: True
    SCALE_NEG: 40.0
    SCALE_POS: 2.0
  NAME: ce_loss
MODEL:
  BACKBONE:
    LR_MUL: 1.0
    NAME: asym_alexnet
  DEVICE: cuda
  HEAD:
    DIM: 10
    IN_CHANNEL: 1024
    LR_MUL: 1.0
    NAME: linear_norm
  PRETRAIN: none
  PRETRIANED_PATH: /data/home/shruti/voxceleb/
  WEIGHT: 
SAVE_DIR: /data/home/shruti/voxceleb/fabnet_ldrs_clss_T100_asymalexnet_iter600
SOLVER:
  BASE_LR: 3e-05
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 10000
  FINETURN_MODE_PATH: 
  GAMMA: 0.1
  IS_FINETURN: False
  MAX_ITERS: 600
  MOMENTUM: 0.9
  OPTIMIZER_NAME: Adam
  RNG_SEED: 1
  STEPS: [100000]
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0005
  WEIGHT_DECAY_BIAS: 0.0005
VALIDATION:
  IS_VALIDATION: True
  VERBOSE: 200
10
10
2019-10-29 10:27:44,957 Train INFO: | Dataset Info |datasize: 2990|num_labels: 10|
2019-10-29 10:27:44,957 Train INFO: | Dataset Info |datasize: 369|num_labels: 10|
2019-10-29 10:27:44,965 Train INFO: Start training
2019-10-29 10:27:47,434 Train INFO: Validation
[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9] [2 0 3 4 2 3 0 3 1 4 0 9 4 2 1 0 1 0 0 2]
2019-10-29 10:27:50,679 Train INFO: Best iteration 0: accuracy: 0.060
2019-10-29 10:27:54,117 Train INFO: eta: 0:04:23  iter: 20  time: 0.0895 (0.4539)  data: 0.0748 (0.4360)  loss: 2.3152 (2.3206)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:27:55,943 Train INFO: eta: 0:02:32  iter: 40  time: 0.0904 (0.2726)  data: 0.0742 (0.2549)  loss: 2.3017 (2.3111)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:27:57,765 Train INFO: eta: 0:01:54  iter: 60  time: 0.0912 (0.2121)  data: 0.0744 (0.1948)  loss: 2.3034 (2.3090)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:27:59,573 Train INFO: eta: 0:01:34  iter: 80  time: 0.0896 (0.1817)  data: 0.0747 (0.1646)  loss: 2.3036 (2.3076)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:01,391 Train INFO: eta: 0:01:21  iter: 100  time: 0.0908 (0.1635)  data: 0.0741 (0.1465)  loss: 2.2980 (2.3057)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:03,221 Train INFO: eta: 0:01:12  iter: 120  time: 0.0914 (0.1515)  data: 0.0745 (0.1345)  loss: 2.2858 (2.3012)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:05,049 Train INFO: eta: 0:01:05  iter: 140  time: 0.0924 (0.1429)  data: 0.0745 (0.1259)  loss: 2.1740 (2.2846)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:06,872 Train INFO: eta: 0:01:00  iter: 160  time: 0.0907 (0.1364)  data: 0.0738 (0.1193)  loss: 2.1391 (2.2666)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:08,703 Train INFO: eta: 0:00:55  iter: 180  time: 0.0907 (0.1315)  data: 0.0742 (0.1143)  loss: 2.0997 (2.2489)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:10,531 Train INFO: eta: 0:00:50  iter: 200  time: 0.0912 (0.1275)  data: 0.0749 (0.1104)  loss: 2.0675 (2.2311)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:10,532 Train INFO: Validation
[4 4 0 4 4 1 8 4 5 3 5 0 5 0 5 0 5 4 0 5] [4 3 0 2 4 0 6 4 5 6 7 0 9 1 9 2 4 4 0 9]
2019-10-29 10:28:11,804 Train INFO: Best iteration 200: accuracy: 0.447
2019-10-29 10:28:18,589 Train INFO: eta: 0:00:57  iter: 220  time: 0.0914 (0.1525)  data: 0.0753 (0.1355)  loss: 2.0482 (2.2141)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:20,413 Train INFO: eta: 0:00:53  iter: 240  time: 0.0905 (0.1474)  data: 0.0748 (0.1304)  loss: 1.9931 (2.1964)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:22,244 Train INFO: eta: 0:00:48  iter: 260  time: 0.0910 (0.1431)  data: 0.0739 (0.1261)  loss: 1.9836 (2.1805)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:24,067 Train INFO: eta: 0:00:44  iter: 280  time: 0.0901 (0.1394)  data: 0.0739 (0.1223)  loss: 1.9513 (2.1645)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:25,883 Train INFO: eta: 0:00:40  iter: 300  time: 0.0908 (0.1361)  data: 0.0725 (0.1190)  loss: 1.9421 (2.1499)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:27,701 Train INFO: eta: 0:00:37  iter: 320  time: 0.0909 (0.1333)  data: 0.0751 (0.1162)  loss: 1.9239 (2.1360)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:29,531 Train INFO: eta: 0:00:34  iter: 340  time: 0.0920 (0.1309)  data: 0.0752 (0.1138)  loss: 1.9070 (2.1227)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:31,354 Train INFO: eta: 0:00:30  iter: 360  time: 0.0915 (0.1286)  data: 0.0755 (0.1116)  loss: 1.8784 (2.1096)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:33,178 Train INFO: eta: 0:00:27  iter: 380  time: 0.0907 (0.1267)  data: 0.0740 (0.1097)  loss: 1.8791 (2.0971)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:34,997 Train INFO: eta: 0:00:24  iter: 400  time: 0.0904 (0.1249)  data: 0.0739 (0.1079)  loss: 1.8483 (2.0847)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:34,998 Train INFO: Validation
[0 4 0 8 4 8 2 9 5 4 5 4 0 1 8 8 7 4 1 0] [4 4 0 8 3 6 2 9 9 4 5 4 1 1 8 6 7 4 0 0]
2019-10-29 10:28:36,287 Train INFO: Best iteration 400: accuracy: 0.699
2019-10-29 10:28:43,562 Train INFO: eta: 0:00:25  iter: 420  time: 0.0910 (0.1393)  data: 0.0745 (0.1224)  loss: 1.8462 (2.0731)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:45,394 Train INFO: eta: 0:00:21  iter: 440  time: 0.0909 (0.1372)  data: 0.0729 (0.1202)  loss: 1.8157 (2.0616)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:47,226 Train INFO: eta: 0:00:18  iter: 460  time: 0.0915 (0.1352)  data: 0.0748 (0.1182)  loss: 1.8221 (2.0513)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:49,049 Train INFO: eta: 0:00:16  iter: 480  time: 0.0908 (0.1334)  data: 0.0741 (0.1163)  loss: 1.7939 (2.0409)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:50,871 Train INFO: eta: 0:00:13  iter: 500  time: 0.0914 (0.1317)  data: 0.0753 (0.1147)  loss: 1.7867 (2.0308)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:52,709 Train INFO: eta: 0:00:10  iter: 520  time: 0.0918 (0.1301)  data: 0.0750 (0.1131)  loss: 1.7600 (2.0207)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:54,531 Train INFO: eta: 0:00:07  iter: 540  time: 0.0908 (0.1287)  data: 0.0743 (0.1117)  loss: 1.7638 (2.0111)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:56,367 Train INFO: eta: 0:00:05  iter: 560  time: 0.0915 (0.1274)  data: 0.0748 (0.1103)  loss: 1.7548 (2.0024)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:58,178 Train INFO: eta: 0:00:02  iter: 580  time: 0.0901 (0.1261)  data: 0.0760 (0.1092)  loss: 1.7388 (1.9935)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:28:59,985 Train INFO: eta: 0:00:00  iter: 600  time: 0.0902 (0.1249)  data: 0.0767 (0.1081)  loss: 1.7214 (1.9846)  lr: 0.000030  max mem: 2.8 GB
2019-10-29 10:29:00,042 Train INFO: Total training time: 0:01:15.076982 (0.1251 s / it)
2019-10-29 10:29:00,042 Train INFO: Best iteration: 000400 | best recall 0.6991869918699187 
