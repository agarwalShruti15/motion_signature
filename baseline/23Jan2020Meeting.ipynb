{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from test_repo_biometric import *\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the file names\n",
    "train_files, test_files = train_test_all_ids('/data/home/shruti/voxceleb/vgg/leaders/')\n",
    "all_lbls = list(train_files.keys())\n",
    "all_lbls.sort()\n",
    "all_lbls = np.array(all_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo for only leaders\n",
    "def get_train_repo1(params):\n",
    "    \n",
    "    out_repo = {}\n",
    "    if params['istrain']:\n",
    "        out_repo = build_repo(params['bsfldr'], \n",
    "                          {f: train_files[f] for f in ['bo','br','bs','cb','dt','ew','hc','jb','kh', 'pb']}, \n",
    "                          {'frames': params['frames'], 'step': params['steps'], 'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                          in_dict=out_repo)\n",
    "    else:\n",
    "        out_repo['real'] = {}; out_repo['fake'] = {}; \n",
    "        for r_or_f in ['real', 'fake']:\n",
    "\n",
    "            out_repo[r_or_f] = build_repo(params['bsfldr'], \n",
    "                                  {f: test_files[r_or_f][f] for f in ['bo','bs','dt','ew','hc','jb']}, \n",
    "                                  {'frames': params['frames'], 'step': params['steps'], 'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                                          in_dict=out_repo[r_or_f])\n",
    "    return out_repo\n",
    "\n",
    "# repo with leaders + ff original \n",
    "def get_train_repo2(params):\n",
    "\n",
    "    out_repo = {}\n",
    "    if params['istrain']:\n",
    "        \n",
    "        # ff original\n",
    "        out_repo = build_repo(params['bsfldr'], \n",
    "                      {'FF_{0:03d}'.format(f): train_files['FF_{0:03d}'.format(f)] for f in range(1000)}, \n",
    "                      {'frames': params['frames'], 'step': params['steps'], 'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':0.5}, \n",
    "                      in_dict=out_repo)\n",
    "        # leaders\n",
    "        out_repo = build_repo(params['bsfldr'], \n",
    "                          {f: train_files[f] for f in ['bo','br','bs','cb','dt','ew','hc','jb','kh', 'pb']}, \n",
    "                          {'frames': params['frames'], 'step': params['steps'], 'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                          in_dict=out_repo)\n",
    "        \n",
    "    else:\n",
    "        out_repo['real'] = {}; out_repo['fake'] = {}; \n",
    "        for r_or_f in ['real', 'fake']:\n",
    "            \n",
    "            # leaders\n",
    "            out_repo[r_or_f] = build_repo(params['bsfldr'], \n",
    "                                          {f: test_files[r_or_f][f] for f in ['bo','bs','dt','ew','hc','jb']}, \n",
    "                                          {'frames': params['frames'], 'step': params['steps'], 'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                                          in_dict=out_repo[r_or_f])\n",
    "            # ff original\n",
    "            out_repo[r_or_f] = build_repo(params['bsfldr'], \n",
    "                                          {'FF_{0:03d}'.format(f): test_files[r_or_f]['FF_{0:03d}'.format(f)] for f in range(1000)}, \n",
    "                                          {'frames': params['frames'], 'step': params['steps'], 'pool_func': np.mean, 'N': 5000, 'n1':0.5, 'n2':1}, \n",
    "                                          in_dict=out_repo[r_or_f])\n",
    "    return out_repo\n",
    "\n",
    "\n",
    "# repo with leaders + ff original + imposters \n",
    "def get_train_repo3(params):\n",
    "    \n",
    "    out_repo = {}\n",
    "    if params['istrain']:\n",
    "        # leaders\n",
    "        out_repo = build_repo(params['bsfldr'], \n",
    "                          {f: train_files[f] for f in ['bo','br','bs','cb','dt','ew','hc','jb','kh', 'pb',\n",
    "                                                      'bo_imposter','bs_imposter','ew_imposter','dt_imposter',\n",
    "                                                       'hc_imposter', 'jb_imposter']}, \n",
    "                          {'frames': params['frames'], 'step': params['steps'], 'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                          in_dict=out_repo)\n",
    "        # ff original\n",
    "        out_repo = build_repo(params['bsfldr'], \n",
    "                      {'FF_{0:03d}'.format(f): train_files['FF_{0:03d}'.format(f)] for f in range(1000)}, \n",
    "                      {'frames': params['frames'], 'step': params['steps'], 'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':0.5}, \n",
    "                      in_dict=out_repo)\n",
    "    else:\n",
    "        out_repo['real'] = {}; out_repo['fake'] = {}; \n",
    "        for r_or_f in ['real', 'fake']:\n",
    "            \n",
    "            # leaders\n",
    "            out_repo[r_or_f] = build_repo(params['bsfldr'], \n",
    "                                          {f: test_files[r_or_f][f] for f in ['bo','bs','dt','ew','hc','jb']}, \n",
    "                                          {'frames': params['frames'], 'step': params['steps'], 'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                                          in_dict=out_repo[r_or_f])\n",
    "            # ff original\n",
    "            out_repo[r_or_f] = build_repo(params['bsfldr'], \n",
    "                                          {'FF_{0:03d}'.format(f): test_files[r_or_f]['FF_{0:03d}'.format(f)] for f in range(1000)}, \n",
    "                                          {'frames': params['frames'], 'step': params['steps'], 'pool_func': np.mean, 'N': 5000, 'n1':0.5, 'n2':1}, \n",
    "                                          in_dict=out_repo[r_or_f])\n",
    "    return out_repo\n",
    "\n",
    "# repo with leaders + ff original + imposters \n",
    "def get_train_repo3_notest(params):\n",
    "    \n",
    "    out_repo = {}\n",
    "    # leaders\n",
    "    out_repo = build_repo(params['bsfldr'], \n",
    "                      {f: train_files[f] for f in ['bo','br','bs','cb','dt','ew','hc','jb','kh', 'pb',\n",
    "                                                  'bo_imposter','bs_imposter','ew_imposter','dt_imposter',\n",
    "                                                   'hc_imposter', 'jb_imposter']}, \n",
    "                      {'frames': params['frames'], 'step': params['steps'], 'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                      in_dict=out_repo)\n",
    "    # ff original\n",
    "    out_repo = build_repo(params['bsfldr'], \n",
    "                  {'FF_{0:03d}'.format(f): train_files['FF_{0:03d}'.format(f)] for f in range(1000)}, \n",
    "                  {'frames': params['frames'], 'step': params['steps'], 'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':0.5}, \n",
    "                  in_dict=out_repo)\n",
    "    \n",
    "    return out_repo\n",
    "\n",
    "# repo with leaders + ff original + imposters + Google\n",
    "def get_train_repo4(params):\n",
    "    \n",
    "    out_repo = {}\n",
    "    # leaders\n",
    "    out_repo = build_repo(params['bsfldr'], \n",
    "                      {f: train_files[f] for f in ['bo','br','bs','cb','dt','ew','hc','jb','kh', 'pb',\n",
    "                                                  'bo_imposter','bs_imposter','ew_imposter','dt_imposter',\n",
    "                                                   'hc_imposter', 'jb_imposter']}, \n",
    "                      {'frames': params['frames'], 'step': params['steps'], \n",
    "                       'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                      in_dict=out_repo)\n",
    "    # ff original\n",
    "    out_repo = build_repo(params['bsfldr'], \n",
    "                  {'FF_{0:03d}'.format(f): train_files['FF_{0:03d}'.format(f)] for f in range(1000)}, \n",
    "                  {'frames': params['frames'], 'step': params['steps'], \n",
    "                   'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':0.5}, \n",
    "                  in_dict=out_repo)\n",
    "\n",
    "    # Google \n",
    "    out_repo = build_repo(params['bsfldr'], \n",
    "                  {'GG_{0:02d}'.format(f+1): train_files['GG_{0:02d}'.format(f+1)] for f in range(28)}, \n",
    "                  {'frames': params['frames'], 'step': params['steps'], \n",
    "                   'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                  in_dict=out_repo)\n",
    "    \n",
    "    # steve + jennifer\n",
    "    out_repo = build_repo(params['bsfldr'], \n",
    "                  {'steve_b': train_files['steve_b']}, \n",
    "                  {'frames': params['frames'], 'step': params['steps'], \n",
    "                   'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                  in_dict=out_repo)\n",
    "    out_repo = build_repo(params['bsfldr'], \n",
    "                  {'jen_l': train_files['jen_l']}, \n",
    "                  {'frames': params['frames'], 'step': params['steps'], \n",
    "                   'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                  in_dict=out_repo)\n",
    "    \n",
    "    kdd_repo=build_kdd(out_repo, all_lbls, k=1)\n",
    "\n",
    "    return kdd_repo\n",
    "\n",
    "def get_result_df(in_train_repo, in_test_repo):\n",
    "    \n",
    "    out_result_df = {}\n",
    "    for r_or_f in ['real', 'fake']:\n",
    "\n",
    "        r_or_f_res = {}\n",
    "        \n",
    "        test_keys = np.sort(list(in_test_repo[r_or_f].keys()))\n",
    "        for ids in test_keys:\n",
    "\n",
    "            cur_max, cur_pred_id = get_repo_dist(in_train_repo, in_test_repo[r_or_f][ids])\n",
    "            r_or_f_res[ids] = pd.DataFrame(data=cur_max, columns=['dist'])\n",
    "            r_or_f_res[ids]['predLabel'] = cur_pred_id\n",
    "            r_or_f_res[ids]['actualLabel'] = ids\n",
    "            r_or_f_res[ids]['RealFake'] = r_or_f\n",
    "\n",
    "        out_result_df[r_or_f] = pd.concat([r_or_f_res[f] for f in test_keys], ignore_index=True, sort=False)\n",
    "\n",
    "    return pd.concat([out_result_df[f] for f in ['real', 'fake']], ignore_index=True, sort=False)\n",
    "\n",
    "\n",
    "def get_result_df_withnotest(in_train_repo, params):\n",
    "    \n",
    "    out_result_df = {}\n",
    "    for r_or_f in ['real', 'fake']:\n",
    "\n",
    "        r_or_f_res = {}\n",
    "        \n",
    "        test_keys = np.sort(list(test_files[r_or_f].keys()))\n",
    "        for ids in test_keys:\n",
    "            cur_test = {}\n",
    "            cur_test = build_repo(params['bsfldr'], \n",
    "                                  {ids: test_files[r_or_f][ids]}, \n",
    "                                  {'frames': params['frames'], 'step': params['steps'], \n",
    "                                   'pool_func': np.mean, 'N': 5000, \n",
    "                                   'n1':0.5 if 'FF_' in ids else 0, 'n2':1}, \n",
    "                                  in_dict=cur_test)\n",
    "\n",
    "            cur_pred_id = get_kdd_dist(in_train_repo, cur_test[ids])\n",
    "            r_or_f_res[ids] = pd.DataFrame(data=cur_pred_id, columns=['predLabel'])\n",
    "            r_or_f_res[ids]['actualLabel'] = ids\n",
    "            r_or_f_res[ids]['RealFake'] = r_or_f\n",
    "\n",
    "        out_result_df[r_or_f] = pd.concat([r_or_f_res[f] for f in test_keys], ignore_index=True, sort=False)\n",
    "\n",
    "    return pd.concat([out_result_df[f] for f in ['real', 'fake']], ignore_index=True, sort=False)\n",
    "\n",
    "\n",
    "def get_result_compression(in_train_repo, params):\n",
    "    \n",
    "    out_result_df = {}\n",
    "    for r_or_f in ['real', 'fake']:\n",
    "\n",
    "        r_or_f_res = {}\n",
    "        \n",
    "        test_keys = np.sort(['bo','bs','dt','ew','hc','jb'])\n",
    "        for ids in test_keys:\n",
    "            cur_test = {}\n",
    "            cur_test = build_repo(params['bsfldr'], \n",
    "                                  {ids: test_files[r_or_f][ids]}, \n",
    "                                  {'frames': params['frames'], 'step': params['steps'], \n",
    "                                   'pool_func': np.mean, 'N': 5000, \n",
    "                                   'n1':0.5 if 'FF_' in ids else 0, 'n2':1}, \n",
    "                                  in_dict=cur_test)\n",
    "\n",
    "            cur_max, cur_pred_id = get_repo_dist(in_train_repo, cur_test[ids])\n",
    "            r_or_f_res[ids] = pd.DataFrame(data=cur_max, columns=['dist'])\n",
    "            r_or_f_res[ids]['predLabel'] = cur_pred_id\n",
    "            r_or_f_res[ids]['actualLabel'] = ids\n",
    "            r_or_f_res[ids]['RealFake'] = r_or_f\n",
    "\n",
    "        out_result_df[r_or_f] = pd.concat([r_or_f_res[f] for f in test_keys], ignore_index=True, sort=False)\n",
    "\n",
    "    return pd.concat([out_result_df[f] for f in ['real', 'fake']], ignore_index=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo with only leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo with leaders\n",
    "repo_leaders = get_train_repo1({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':100, 'steps':5})\n",
    "test_emb = get_train_repo1({'istrain':False, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':100, 'steps':5})\n",
    "vgg_repo1 = get_result_df(repo_leaders, test_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_leaders = []; test_emb = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo of Leaders plus Face Forensics Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo with leaders\n",
    "repo_leaders_ff = get_train_repo2({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':100, 'steps':5})\n",
    "test_emb_ff = get_train_repo2({'istrain':False, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':100, 'steps':5})\n",
    "vgg_repo2 = get_result_df(repo_leaders_ff, test_emb_ff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_leaders_ff = []; test_emb_ff = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo of Leaders + Face Forensics Original + Imposters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo with leaders\n",
    "repo = get_train_repo3({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':100, 'steps':5})\n",
    "test_emb = get_train_repo3({'istrain':False, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':100, 'steps':5})\n",
    "vgg_repo3 = get_result_df(repo, test_emb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders\n",
    "repo = get_train_repo4({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':100, 'steps':5})\n",
    "vgg_repo4 = get_result_df_withnotest(repo, {'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':100, 'steps':5})\n",
    "vgg_repo4.to_csv('results100_vgg.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressed Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders\n",
    "repo = get_train_repo4({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':100, 'steps':5})\n",
    "vgg_results_comp = get_result_compression(repo, {'istrain':False, 'bsfldr':'/data/home/shruti/voxceleb/vgg/compression/', \n",
    "                                'frames':100, 'steps':5})\n",
    "vgg_results_comp.to_csv('results100_vgg_comp.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25 Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders\n",
    "repo = get_train_repo4({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':25, 'steps':5})\n",
    "vgg_results_25 = get_result_df_withnotest(repo, {'istrain':False, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':25, 'steps':5})\n",
    "vgg_results_25.to_csv('results25_vgg.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders\n",
    "repo = get_train_repo4({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':50, 'steps':5})\n",
    "vgg_results_50 = get_result_df_withnotest(repo, {'istrain':False, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':50, 'steps':5})\n",
    "vgg_results_50.to_csv('results50_vgg.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75 Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders\n",
    "repo = get_train_repo4({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':75, 'steps':5})\n",
    "vgg_results_75 = get_result_df_withnotest(repo, {'istrain':False, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':75, 'steps':5})\n",
    "vgg_results_75.to_csv('results75_vgg.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Time Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders\n",
    "repo = get_train_repo4({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':1, 'steps':5})\n",
    "vgg_results_1 = get_result_df_withnotest(repo, {'istrain':False, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':1, 'steps':5})\n",
    "vgg_results_1.to_csv('results1_vgg.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fabnet Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo with only leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo with leaders\n",
    "repo_leaders = get_train_repo1({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric/', \n",
    "                                'frames':1, 'steps':1})\n",
    "test_emb = get_train_repo1({'istrain':False, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric/', \n",
    "                                'frames':1, 'steps':1})\n",
    "fabnet_repo1 = get_result_df(repo_leaders, test_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_leaders = []; test_emb = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo of Leaders plus Face Forensics Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo with leaders\n",
    "repo_leaders_ff = get_train_repo2({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric/', \n",
    "                                'frames':1, 'steps':1})\n",
    "test_emb_ff = get_train_repo2({'istrain':False, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric/', \n",
    "                                'frames':1, 'steps':1})\n",
    "fabnet_repo2 = get_result_df(repo_leaders_ff, test_emb_ff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_leaders_ff = []; test_emb_ff = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo of Leaders + Face Forensics Original + Imposters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo with leaders\n",
    "repo = get_train_repo3_notest({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric/', \n",
    "                                'frames':1, 'steps':1})\n",
    "fabnet_repo3 = get_result_df_withnotest(repo, {'istrain':False, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric/', \n",
    "                                'frames':1, 'steps':1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = []; test_emb = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo of Leaders + Face Forensics Original + Imposters + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo with leaders\n",
    "repo = get_train_repo4({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric/', \n",
    "                                'frames':1, 'steps':1})\n",
    "fabnet_repo4 = get_result_df_withnotest(repo, {'istrain':False, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric/', \n",
    "                                'frames':1, 'steps':1})\n",
    "fabnet_repo4.to_csv('results100_fabnet.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressed Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders\n",
    "repo = get_train_repo4({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric/', \n",
    "                                'frames':1, 'steps':1})\n",
    "fabnet_results_comp = get_result_compression(repo, {'istrain':False, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric_compression/', \n",
    "                                'frames':1, 'steps':1})\n",
    "\n",
    "fabnet_results_comp.to_csv('results100_fabnet_comp.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25 Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders\n",
    "repo = get_train_repo4({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric25/', \n",
    "                                'frames':1, 'steps':1})\n",
    "fabnet_results_25 = get_result_df_withnotest(repo, {'istrain':False, \n",
    "                                                    'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric25/', \n",
    "                                'frames':1, 'steps':1})\n",
    "\n",
    "fabnet_results_25.to_csv('results25_fabnet.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders\n",
    "repo = get_train_repo4({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric50/', \n",
    "                                'frames':1, 'steps':1})\n",
    "fabnet_results_50 = get_result_df_withnotest(repo, {'istrain':False, \n",
    "                                                    'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric50/', \n",
    "                                'frames':1, 'steps':1})\n",
    "\n",
    "fabnet_results_50.to_csv('results50_fabnet.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75 Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders\n",
    "repo = get_train_repo4({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric75/', \n",
    "                                'frames':1, 'steps':1})\n",
    "fabnet_results_75 = get_result_df_withnotest(repo, {'istrain':False, \n",
    "                                                    'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric75/', \n",
    "                                'frames':1, 'steps':1})\n",
    "\n",
    "fabnet_results_75.to_csv('results75_fabnet.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Time Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders\n",
    "repo = get_train_repo4({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet/leaders/', \n",
    "                                'frames':1, 'steps':5})\n",
    "fabnet_results_1 = get_result_df_withnotest(repo, {'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet/leaders/', \n",
    "                                'frames':1, 'steps':5})\n",
    "fabnet_results_1.to_csv('results1_fabnet.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with only leaders in repository\n",
    "# if we had leaders in the repo and we get the face-swap of leaders dist\n",
    "# how we do on Leader Faceswap\n",
    "def get_auc(in_result_df, real_nm, fake_nm):\n",
    "    \n",
    "    real_dist = in_result_df.loc[np.logical_and(in_result_df['actualLabel'].isin(real_nm), \n",
    "                                                in_result_df['RealFake']=='real'), 'dist']\n",
    "    \n",
    "    fake_dist = in_result_df.loc[np.logical_and(in_result_df['actualLabel'].isin(fake_nm), \n",
    "                                                in_result_df['RealFake']=='fake'), 'dist']\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(np.concatenate((np.ones((len(real_dist), )), \n",
    "                                                    np.zeros((len(fake_dist), )) )), \n",
    "                                     np.concatenate((real_dist, \n",
    "                                                     fake_dist)))\n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "def get_dis_accuracy(df2, real_nm, fake_nm):\n",
    "    \n",
    "    # real accuracy\n",
    "    r1 = df2.loc[np.logical_and(df2['actualLabel'].isin(real_nm), \n",
    "                                df2['RealFake']=='real'), 'actualLabel']\n",
    "    r2 = df2.loc[np.logical_and(df2['actualLabel'].isin(real_nm), \n",
    "                                df2['RealFake']=='real'), 'predLabel']\n",
    "    real_acc = len(np.argwhere(r1 == r2).ravel())/len(r1)\n",
    "    \n",
    "    # fake accuracy\n",
    "    f1 = df2.loc[np.logical_and(df2['actualLabel'].isin(fake_nm), \n",
    "                                df2['RealFake']=='fake'), 'actualLabel']\n",
    "    f2 = df2.loc[np.logical_and(df2['actualLabel'].isin(fake_nm), \n",
    "                                df2['RealFake']=='fake'), 'predLabel']\n",
    "    fake_acc = len(np.argwhere(f1 != f2).ravel())/len(f1)\n",
    "    \n",
    "    return real_acc, fake_acc\n",
    "\n",
    "\n",
    "def get_four_measures(cur_df1, cur_df2):\n",
    "    \n",
    "    out_res = np.zeros((2, 4))\n",
    "    out_res[0, 0] = len(np.argwhere((np.array(cur_df1['predLabel']) == np.array(cur_df2['predLabel']))\n",
    "                    & (np.array(cur_df2['predLabel']) == np.array(cur_df2['actualLabel']))).ravel())\n",
    "    \n",
    "    out_res[0, 1] = len(np.argwhere((np.array(cur_df1['predLabel']) == np.array(cur_df2['predLabel'])) \n",
    "                                    & (np.array(cur_df2['predLabel']) != np.array(cur_df2['actualLabel'])) \n",
    "                                    & (np.array(cur_df1['predLabel']) != np.array(cur_df1['actualLabel']))).ravel())\n",
    "    \n",
    "    out_res[1, 1] = len(np.argwhere((np.array(cur_df1['predLabel']) != np.array(cur_df2['predLabel'])) \n",
    "                                    & (np.array(cur_df2['predLabel']) != np.array(cur_df2['actualLabel'])) \n",
    "                                    & (np.array(cur_df1['predLabel']) != np.array(cur_df1['actualLabel']))).ravel())\n",
    "    \n",
    "    \n",
    "    out_res[1, 2] = len(np.argwhere((np.array(cur_df1['predLabel']) != np.array(cur_df2['predLabel'])) \n",
    "                                & (np.array(cur_df2['predLabel']) != np.array(cur_df2['actualLabel'])) \n",
    "                                & (np.array(cur_df1['predLabel']) == np.array(cur_df1['actualLabel']))).ravel())\n",
    "    \n",
    "    out_res[1, 3] = len(np.argwhere((np.array(cur_df1['predLabel']) != np.array(cur_df2['predLabel'])) \n",
    "                            & (np.array(cur_df2['predLabel']) == np.array(cur_df2['actualLabel'])) \n",
    "                            & (np.array(cur_df1['predLabel']) != np.array(cur_df1['actualLabel']))).ravel())\n",
    "    \n",
    "    return out_res\n",
    "\n",
    "\n",
    "def get_discrepany_accuracy(df1, df2, real_nm, fake_nm):\n",
    "    \n",
    "    out_result = {}\n",
    "    # true label\n",
    "    out_result['real'] = np.zeros((2, 4)) # pred values (real,fake), (VGG_c-Fab_c, VGG_i-Fab_i, VGG_c-Fab_i, VGG_i-Fab_c)\n",
    "    out_result['fake'] = np.zeros((2, 4))\n",
    "    \n",
    "    # real accuracy df1\n",
    "    for k in real_nm:\n",
    "        \n",
    "        cur_df1 = df1[(df1['actualLabel']==k) & (df1['RealFake']=='real')]\n",
    "        cur_df2 = df2[(df2['actualLabel']==k) & (df2['RealFake']=='real')]\n",
    "        n = np.min([len(cur_df1), len(cur_df2)])\n",
    "        cur_df1 = cur_df1.iloc[:n, :].copy()\n",
    "        cur_df2 = cur_df2.iloc[:n, :].copy()\n",
    "        \n",
    "        # real prediction count\n",
    "        out_result['real'] = out_result['real'] + get_four_measures(cur_df1, cur_df2)\n",
    "    \n",
    "    for k in fake_nm:\n",
    "        \n",
    "        cur_df1 = df1[(df1['actualLabel']==k) & (df1['RealFake']=='fake')]\n",
    "        cur_df2 = df2[(df2['actualLabel']==k) & (df2['RealFake']=='fake')]\n",
    "        n = np.min([len(cur_df1), len(cur_df2)])\n",
    "        cur_df1 = cur_df1.iloc[:n, :].copy()\n",
    "        cur_df2 = cur_df2.iloc[:n, :].copy()\n",
    "        \n",
    "        # real prediction count\n",
    "        out_result['fake'] = out_result['fake'] + get_four_measures(cur_df1, cur_df2)\n",
    "            \n",
    "    return out_result\n",
    "    \n",
    "    \n",
    "def plot_dist(in_result_df, real_nm, fake_nm, ax, title):\n",
    "    \n",
    "    sns.distplot(np.log(in_result_df.loc[np.logical_and(in_result_df['actualLabel'].isin(real_nm), \n",
    "                                                in_result_df['RealFake']=='real'), 'dist']), \n",
    "                 bins=np.log(np.linspace(0.1, 1, 30)), label='real', ax=ax)\n",
    "    sns.distplot(np.log(in_result_df.loc[np.logical_and(in_result_df['actualLabel'].isin(fake_nm), \n",
    "                                                in_result_df['RealFake']=='fake'), 'dist']), \n",
    "                 bins=np.log(np.linspace(0.1, 1, 30)), label='fake', ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim([np.log(0.1), np.log(1)])\n",
    "    ax.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrepancy Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(in_res_o):\n",
    "    \n",
    "    in_res = {}\n",
    "    in_res['real'] = in_res_o['real']*100/np.sum(in_res_o['real'])\n",
    "    in_res['fake'] = in_res_o['fake']*100/np.sum(in_res_o['fake'])\n",
    "    print('\\t True Positve: {0:3.2f} True Negative: {1:3.2f}\\n'.format(in_res['real'][0,0], \n",
    "                                                                    in_res['fake'][1,2]+\n",
    "                                                                    in_res['fake'][1,1]+\n",
    "                                                                    in_res['fake'][1,3]))\n",
    "    print('\\t \\t VGG_c-Fab_c \\t VGG_i-Fab_i \\t VGG_c-Fab_i \\t VGG_i-Fab_c \\n')\n",
    "    print('Real->Real \\t {0:3.2f} \\t\\t {1:3.2f} \\t\\t {2:3.2f} \\t\\t {3:3.2f} \\n'.format(in_res['real'][0, 0],\n",
    "                                                                               in_res['real'][0, 1],\n",
    "                                                                               in_res['real'][0, 2],\n",
    "                                                                               in_res['real'][0, 3]))\n",
    "    print('Real->Fake \\t {0:3.2f} \\t\\t {1:3.2f} \\t\\t {2:3.2f} \\t\\t {3:3.2f} \\n'.format(in_res['real'][1, 0],\n",
    "                                                                               in_res['real'][1, 1],\n",
    "                                                                               in_res['real'][1, 2],\n",
    "                                                                               in_res['real'][1, 3]))\n",
    "    print('Fake->Real \\t {0:3.2f} \\t\\t {1:3.2f} \\t\\t {2:3.2f} \\t\\t {3:3.2f} \\n'.format(in_res['fake'][0, 0],\n",
    "                                                                               in_res['fake'][0, 1],\n",
    "                                                                               in_res['fake'][0, 2],\n",
    "                                                                               in_res['fake'][0, 3]))\n",
    "    print('Fake->Fake \\t {0:3.2f} \\t\\t {1:3.2f} \\t\\t {2:3.2f} \\t\\t {3:3.2f} \\n'.format(in_res['fake'][1, 0],\n",
    "                                                                               in_res['fake'][1, 1],\n",
    "                                                                               in_res['fake'][1, 2],\n",
    "                                                                               in_res['fake'][1, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (VGG + Fabnet Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Leaders + FF original + Imposters + Google \\n')\n",
    "\n",
    "print('\\t Leaders \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_repo4, fabnet_repo4,\n",
    "                                     ['bo','bs','dt','ew','hc','jb'], \n",
    "                                     ['bo','bs','dt','ew','hc','jb']))\n",
    "print('\\t FaceForensics \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_repo4, fabnet_repo4,\n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)]))\n",
    "print('\\t Google \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_repo4, fabnet_repo4,\n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)]))\n",
    "print('\\t ALL \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_repo4, fabnet_repo4,\n",
    "                        test_files['real'].keys(), \n",
    "                        test_files['fake'].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Time (VGG + Fabnet Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t Leaders \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_1, fabnet_results_1,\n",
    "                                     ['bo','bs','dt','ew','hc','jb'], \n",
    "                                     ['bo','bs','dt','ew','hc','jb']))\n",
    "print('\\t FaceForensics \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_1, fabnet_results_1,\n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)]))\n",
    "print('\\t Google \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_1, fabnet_results_1,\n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)]))\n",
    "print('\\t ALL \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_1, fabnet_results_1,\n",
    "                        test_files['real'].keys(), \n",
    "                        test_files['fake'].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('\\t Leaders \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_comp, fabnet_results_comp,\n",
    "                                     ['bo','bs','dt','ew','hc','jb'], \n",
    "                                     ['bo','bs','dt','ew','hc','jb']))\n",
    "\"\"\"print('\\t FaceForensics \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_comp, fabnet_results_comp,\n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)]))\n",
    "print('\\t Google \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_comp, fabnet_results_comp,\n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)]))\n",
    "print('\\t ALL \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_comp, fabnet_results_comp,\n",
    "                        test_files['real'].keys(), \n",
    "                        test_files['fake'].keys()))\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25 VGG + Fabnet Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Leaders + FF original + Imposters + Google \\n')\n",
    "\n",
    "print('\\t Leaders \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_25, fabnet_results_25,\n",
    "                                     ['bo','bs','dt','ew','hc','jb'], \n",
    "                                     ['bo','bs','dt','ew','hc','jb']))\n",
    "print('\\t FaceForensics \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_25, fabnet_results_25,\n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)]))\n",
    "print('\\t Google \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_25, fabnet_results_25,\n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)]))\n",
    "print('\\t ALL \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_25, fabnet_results_25,\n",
    "                        test_files['real'].keys(), \n",
    "                        test_files['fake'].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 VGG + Fabnet Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Leaders + FF original + Imposters + Google \\n')\n",
    "\n",
    "print('\\t Leaders \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_50, fabnet_results_50,\n",
    "                                     ['bo','bs','dt','ew','hc','jb'], \n",
    "                                     ['bo','bs','dt','ew','hc','jb']))\n",
    "print('\\t FaceForensics \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_50, fabnet_results_50,\n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)]))\n",
    "print('\\t Google \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_50, fabnet_results_50,\n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)]))\n",
    "print('\\t ALL \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_50, fabnet_results_50,\n",
    "                        test_files['real'].keys(), \n",
    "                        test_files['fake'].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75 VGG + Fabnet Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Leaders + FF original + Imposters + Google \\n')\n",
    "\n",
    "print('\\t Leaders \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_75, fabnet_results_75,\n",
    "                                     ['bo','bs','dt','ew','hc','jb'], \n",
    "                                     ['bo','bs','dt','ew','hc','jb']))\n",
    "print('\\t FaceForensics \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_75, fabnet_results_75,\n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)]))\n",
    "print('\\t Google \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_75, fabnet_results_75,\n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)]))\n",
    "print('\\t ALL \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_75, fabnet_results_75,\n",
    "                        test_files['real'].keys(), \n",
    "                        test_files['fake'].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Only Leaders')\n",
    "print('\\t VGG')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(vgg_repo1, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t Fabnet Metric')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(fabnet_repo1, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "\n",
    "print('Repo Leaders + FF original')\n",
    "print('\\t VGG')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(vgg_repo2, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics {0:0.4f}'.format(get_auc(vgg_repo2, \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "print('\\t Fabnet Metric')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(fabnet_repo2, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics {0:0.4f}'.format(get_auc(fabnet_repo2, \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "\n",
    "\n",
    "print('Repo Leaders + FF original + Imposters')\n",
    "print('\\t VGG')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(vgg_repo3, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics {0:0.4f}'.format(get_auc(vgg_repo3, \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "print('\\t Fabnet Metric')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(fabnet_repo3, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics {0:0.4f}'.format(get_auc(fabnet_repo3, \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Leaders + FF original + Imposters + Google')\n",
    "print('\\t VGG')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(vgg_repo4, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics {0:0.4f}'.format(get_auc(vgg_repo4, \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "print('\\t \\t Google {0:0.4f}'.format(get_auc(vgg_repo4, \n",
    "                                              ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                                              ['GG_{0:02d}'.format(f+1) for f in range(28)])))\n",
    "\n",
    "\n",
    "print('\\t Fabnet Metric')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(fabnet_repo4, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics {0:0.4f}'.format(get_auc(fabnet_repo4, \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "print('\\t \\t Google {0:0.4f}'.format(get_auc(fabnet_repo4, \n",
    "                                              ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                                              ['GG_{0:02d}'.format(f+1) for f in range(28)])))\n",
    "\n",
    "print('\\t Fabnet Pool')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(fabnetPool_repo4, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics {0:0.4f}'.format(get_auc(fabnetPool_repo4, \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "print('\\t \\t Google {0:0.4f}'.format(get_auc(fabnetPool_repo4, \n",
    "                                              ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                                              ['GG_{0:02d}'.format(f+1) for f in range(28)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Only Leaders')\n",
    "print('\\t \\t leaders (real, fake) {}'.format(get_dis_accuracy(vgg_repo1, fabnet_repo1,\n",
    "                                                       ['bo','bs','dt','ew','hc','jb'], \n",
    "                                                       ['bo','bs','dt','ew','hc','jb'])))\n",
    "\n",
    "print('Repo Leaders + FF original')\n",
    "print('\\t \\t leaders (real, fake) {}'.format(get_dis_accuracy(vgg_repo2, fabnet_repo2,\n",
    "                                                       ['bo','bs','dt','ew','hc','jb'], \n",
    "                                                       ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics (real, fake) {}'.format(get_dis_accuracy(vgg_repo2, fabnet_repo2,\n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "\n",
    "print('Repo Leaders + FF original + Imposter')\n",
    "print('\\t \\t leaders (real, fake) {}'.format(get_dis_accuracy(vgg_repo3, fabnet_repo3,\n",
    "                                                       ['bo','bs','dt','ew','hc','jb'], \n",
    "                                                       ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics (real, fake) {}'.format(get_dis_accuracy(vgg_repo3, fabnet_repo3,\n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "\n",
    "\n",
    "print('Repo Leaders + FF original + Imposters + Google')\n",
    "print('\\t \\t leaders (real, fake) {}'.format(get_dis_accuracy(vgg_repo4, fabnet_repo4,\n",
    "                                                       ['bo','bs','dt','ew','hc','jb'], \n",
    "                                                       ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics (real, fake) {}'.format(get_dis_accuracy(vgg_repo4, fabnet_repo4,\n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "print('\\t \\t Google (real, fake) {}'.format(get_dis_accuracy(vgg_repo4, fabnet_repo4,\n",
    "                                                             ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                                                             ['GG_{0:02d}'.format(f+1) for f in range(28)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Leaders + FF original + Imposters + Google')\n",
    "print('\\t \\t leaders (real, fake) {}'.format(get_dis_accuracy(fabnet_repo4,\n",
    "                                                       ['bo','bs','dt','ew','hc','jb'], \n",
    "                                                       ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics (real, fake) {}'.format(get_dis_accuracy(fabnet_repo4,\n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "print('\\t \\t Google (real, fake) {}'.format(get_dis_accuracy(fabnet_repo4,\n",
    "                                                             ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                                                             ['GG_{0:02d}'.format(f+1) for f in range(28)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC\n",
    "\n",
    "|                |Only  Leaders|| Leaders + FaceForensics|| Leaders + FaceForensics + Imposter || \n",
    "|----------------|-----|--------|------------|------------|----------------|--------------------|\n",
    "|                |VGG  | Fabnet |     VGG    |   Fabnet   |     VGG        |     Fabnet         |\n",
    "|                |     |        |            |            |                |                    |\n",
    "|Leaders         |88.6 | 93.3   |    88.6    |    92.7    |      87.9      |         28.7       |\n",
    "|Face Forensics  |NA   | NA     |    99.7    |    98.2    |      99.7      |         98.2       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCURACY\n",
    "\n",
    "|                |Only  Leaders|| Leaders + FaceForensics|| Leaders + FaceForensics + Imposter || \n",
    "|----------------|-------------|--------------|--------------|--------------|--------------|--------------|\n",
    "|                |True Positive| True Negative| True Positive| True Negative| True Positive|True Negative |\n",
    "|                |             |              |              |              |              |              |\n",
    "|Leaders         |99.4         | 26.6         |    98.9      |    39.9      |     97.5     |    99.2      |\n",
    "|Face Forensics  |NA           | NA           |    99.4      |    97.1      |     99.4     |    97.2      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(10,14))\n",
    "\n",
    "plot_dist(vgg_repo4, ['bo','bs','dt','ew','hc','jb'], \n",
    "          ['bo','bs','dt','ew','hc','jb'], \n",
    "          ax[0, 0], 'VGG: Leaders')\n",
    "plot_dist(vgg_repo4, ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "          ['FF_{0:03d}'.format(f) for f in range(1000)], ax[1, 0], \n",
    "          'VGG: FaceForensics')\n",
    "plot_dist(vgg_repo4, ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "          ['GG_{0:02d}'.format(f+1) for f in range(28)], ax[2, 0], \n",
    "          'VGG: Google')\n",
    "\n",
    "plot_dist(fabnet_repo4, ['bo','bs','dt','ew','hc','jb'], \n",
    "          ['bo','bs','dt','ew','hc','jb'], \n",
    "          ax[0, 1], 'Fabnet: Leaders')\n",
    "plot_dist(fabnet_repo4, ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "          ['FF_{0:03d}'.format(f) for f in range(1000)], ax[1, 1], \n",
    "          'Fabnet: FaceForensics')\n",
    "plot_dist(fabnet_repo4, ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "          ['GG_{0:02d}'.format(f+1) for f in range(28)], ax[2, 1], \n",
    "          'Fabnet: Google')\n",
    "plt.subplots_adjust(hspace=0.3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
