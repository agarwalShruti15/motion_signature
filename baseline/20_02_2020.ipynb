{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from repo2 import *\n",
    "import utils as u\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FF, GG, DFDC, Ldr\n",
    "\n",
    "look below for Celeb-DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before 4105\n",
      "after 3739\n"
     ]
    }
   ],
   "source": [
    "# get the file names\n",
    "train_files, test_files = u.train_test_all_ids('/data/home/shruti/voxceleb/vgg/leaders/')\n",
    "all_lbls = list(train_files.keys())\n",
    "all_lbls.sort()\n",
    "all_lbls = np.array(all_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders + ff original + imposters + Google\n",
    "def get_train_repo(params):\n",
    "    \n",
    "    out_repo = Repo2(params['bsfldr'], params['frames'], params['steps'], np.mean, 2000)\n",
    "    out_repo.add_ids({f: train_files[f] for f in ['bo','br','bs','cb','dt','ew','hc','jb','kh', 'pb',\n",
    "                                                  'bo_imposter','bs_imposter','ew_imposter','dt_imposter',\n",
    "                                                   'hc_imposter', 'jb_imposter']}, 0, 1)\n",
    "    out_repo.add_ids({f: train_files[f] for f in train_files.keys() if 'GG_' in f}, 0, 1)\n",
    "    out_repo.add_ids({k: train_files[k] for k in train_files.keys() if 'DFDC_' in k}, 0, 1)\n",
    "    out_repo.add_ids({f: train_files[f] for f in train_files.keys() if 'FF_' in f}, 0, 0.5)    \n",
    "    out_repo.add_ids({f: train_files[f] for f in train_files.keys() if 'CDF_' in f}, 0, 0.5)\n",
    "    out_repo.add_ids({f: train_files[f] for f in train_files.keys() if 'inwild_' in f}, 0, 1)\n",
    "    \n",
    "    \n",
    "    #out_repo.add_ids({'jen_l': train_files['jen_l']}, 0, 1)\n",
    "    \n",
    "    out_repo.build_repo_noKDD()\n",
    "    \n",
    "    return out_repo\n",
    "\n",
    "\n",
    "def save_results(vgg_repo, fab_repo, test_ids, r_or_f, N_f, out_file, n1, n2, parallel=False):\n",
    "        \n",
    "    # number of files per id\n",
    "    test_dict = {}\n",
    "    for ids in test_ids:\n",
    "        cur_test_files = test_files[r_or_f][ids]\n",
    "        if N_f>0 and len(cur_test_files)>N_f:\n",
    "            test_dict[ids] = cur_test_files[:N_f].copy()\n",
    "        else:\n",
    "            test_dict[ids] = cur_test_files.copy()\n",
    "            \n",
    "    vgg_result = vgg_repo.dist_using_dict(test_dict, n1, n2, parallel=parallel)\n",
    "    vgg_result['RealFake'] = r_or_f\n",
    "    fab_result = fab_repo.dist_using_dict(test_dict, n1, n2, parallel=parallel)\n",
    "    fab_result['RealFake'] = r_or_f\n",
    "    full_df = vgg_result.set_index('fileName').join(fab_result.set_index('fileName'), \n",
    "                                                 how='inner', lsuffix='_vgg', rsuffix='_fab')\n",
    "    full_df = full_df[['actualLabel_vgg', \n",
    "                       'RealFake_vgg', 'sim_vgg', 'sim_fab']].copy()\n",
    "    \n",
    "    if out_file is not None:\n",
    "        full_df.to_pickle(out_file)\n",
    "        \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels 1173\n",
      "Build repo time: 10.325 Size: (176137, 4096)\n",
      "/data/home/shruti/voxceleb/fabnet_metric/celeb_real/_id27_0005.npy\n",
      "Number of labels 1173\n",
      "Build repo time: 2.850 Size: (175081, 512)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Repo2' object has no attribute 'label_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-42925b9595b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_repo_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result_csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vgg_repo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfab_repo_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result_csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fab_repo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result_csv/label_dict.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfab_repo_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Repo2' object has no attribute 'label_dict'"
     ]
    }
   ],
   "source": [
    "\n",
    "vgg_repo_metric = get_train_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':100, 'steps':5, 'N_comp':512})\n",
    "fab_repo_metric = get_train_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric/', \n",
    "                                'frames':1, 'steps':1, 'N_comp':-1})\n",
    "\n",
    "# this id is repeating with CDF_id12\n",
    "#vgg_repo_metric.remove_ids(['jen_l'])\n",
    "#fab_repo_metric.remove_ids(['jen_l'])\n",
    "\n",
    "u.save_obj(vgg_repo_metric, 'result_csv', 'vgg_repo')\n",
    "u.save_obj(fab_repo_metric, 'result_csv', 'fab_repo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "u.save_obj(fab_repo_metric.name2label_dict, 'result_csv', 'name2label_dict')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   9 out of   9 | elapsed:   28.8s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   9 out of   9 | elapsed:   10.9s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:    8.1s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   1 out of   1 | elapsed:    8.9s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#inwild sb\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['CDF_id12'], \n",
    "             'real', -1, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/inwild_jl_real_100.csv')\n",
    "\n",
    "#inwild tc\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['inwild_bh'], \n",
    "             'real', -1, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/inwild_bh_real_100.csv')\n",
    "\n",
    "# inwild be\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['inwild_an'], \n",
    "             'real', -1, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/inwild_an_real_100.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   1 out of   1 | elapsed:   12.1s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   1 out of   1 | elapsed:    5.1s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   1 out of   1 | elapsed:    8.7s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   1 out of   1 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   1 out of   1 | elapsed:    8.8s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   1 out of   1 | elapsed:    3.6s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#inwild sb\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['inwild_sb'], \n",
    "             'fake', -1, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/inwild_sb_fake_100.csv')\n",
    "\n",
    "#inwild tc\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['inwild_tc'], \n",
    "             'fake', -1, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/inwild_tc_fake_100.csv')\n",
    "\n",
    "# inwild be\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['inwild_be'], \n",
    "             'fake', -1, \n",
    "             None, 0, 0.5, parallel=True)\n",
    "temp.to_pickle('result_csv/inwild_be_fake_100.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=16)]: Done 247 out of 247 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=16)]: Done 247 out of 247 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=16)]: Done 2418 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=16)]: Done 3168 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=16)]: Done 3739 out of 3739 | elapsed: 52.4min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=16)]: Done 2418 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=16)]: Done 3168 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=16)]: Done 3739 out of 3739 | elapsed: 23.2min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=16)]: Done  55 out of  55 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=16)]: Done  55 out of  55 | elapsed:   25.1s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=16)]: Done 1577 out of 1577 | elapsed: 29.4min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=16)]: Done 1577 out of 1577 | elapsed: 11.4min finished\n"
     ]
    }
   ],
   "source": [
    "vgg_repo_metric.bs_fldr = '/data/home/shruti/voxceleb/vgg/leaders/'\n",
    "fab_repo_metric.bs_fldr = '/data/home/shruti/voxceleb/fabnet_metric/'\n",
    "\n",
    "\n",
    "#DFDC\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'DFDC_' in k], \n",
    "             'real', -1, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/DFDC_real_100.csv')\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'DFDC_' in k], \n",
    "             'fake', -1, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/DFDC_fake_100.csv')\n",
    "\n",
    "# GG\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'GG_' in k], \n",
    "             'real', -1, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/GG_real_100.csv')\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'GG_' in k], \n",
    "             'fake', -1, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/GG_fake_100.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#LEADER\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'real', 10, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/ldr_real_100.csv')\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'fake', 10, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/ldr_fake_100.csv')\n",
    "\n",
    "\n",
    "# FF\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'FF_' in k], \n",
    "             'real', -1, \n",
    "             None, 0.5, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/FF_real_100.csv')\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'FF_' in k], \n",
    "             'fake', -1, \n",
    "             None, 0.5, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/FF_fake_100.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=16)]: Done 591 out of 591 | elapsed:  6.6min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=16)]: Done 591 out of 591 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=16)]: Done 2418 tasks      | elapsed: 25.3min\n",
      "[Parallel(n_jobs=16)]: Done 3168 tasks      | elapsed: 33.2min\n",
      "[Parallel(n_jobs=16)]: Done 4018 tasks      | elapsed: 42.1min\n",
      "[Parallel(n_jobs=16)]: Done 4968 tasks      | elapsed: 52.1min\n",
      "[Parallel(n_jobs=16)]: Done 5639 out of 5639 | elapsed: 59.1min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=16)]: Done 2418 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=16)]: Done 3168 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=16)]: Done 4018 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=16)]: Done 4968 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=16)]: Done 5639 out of 5639 | elapsed: 25.9min finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Celeb-DF\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'CDF_' in k], \n",
    "             'real', -1, \n",
    "             None, 0.5, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/CDF_real_100.csv')\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'CDF_' in k], \n",
    "             'fake', -1, \n",
    "             None, 0.5, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/CDF_fake_100.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_repo_metric = u.load_obj('result_csv', 'vgg_repo')\n",
    "fab_repo_metric = u.load_obj('result_csv', 'fab_repo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_repo_metric.remove_ids(['steve_b'])\n",
    "fab_repo_metric.remove_ids(['steve_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in wild ids \n",
    "vgg_repo_metric.add_ids({f: train_files[f] for f in train_files.keys() if 'inwild_' in f}, 0, 1)\n",
    "vgg_repo_metric.build_repo_noKDD()\n",
    "\n",
    "fab_repo_metric.add_ids({f: train_files[f] for f in train_files.keys() if 'inwild_' in f}, 0, 1)\n",
    "fab_repo_metric.build_repo_noKDD()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fab_repo_metric.label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('result_csv/label_dict.npy', fab_repo_metric.label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=16)]: Done  60 out of  60 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=16)]: Done  60 out of  60 | elapsed:   28.5s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=16)]: Done  57 out of  57 | elapsed:   55.7s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=16)]: Done  57 out of  57 | elapsed:   22.3s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=16)]: Done 247 out of 247 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=16)]: Done 247 out of 247 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=16)]: Done 2418 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=16)]: Done 3168 tasks      | elapsed: 34.6min\n",
      "[Parallel(n_jobs=16)]: Done 3739 out of 3739 | elapsed: 40.8min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=16)]: Done 2418 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=16)]: Done 3168 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=16)]: Done 3739 out of 3739 | elapsed: 18.2min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=16)]: Done 997 out of 997 | elapsed: 10.7min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=16)]: Done 997 out of 997 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=16)]: Done 1988 out of 1988 | elapsed: 20.4min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=16)]: Done 1988 out of 1988 | elapsed:  8.9min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=16)]: Done  55 out of  55 | elapsed:   59.3s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=16)]: Done  55 out of  55 | elapsed:   23.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed: 23.2min\n",
      "[Parallel(n_jobs=16)]: Done 1577 out of 1577 | elapsed: 30.0min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=16)]: Done 1577 out of 1577 | elapsed: 11.8min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=16)]: Done 591 out of 591 | elapsed:  6.0min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=16)]: Done 591 out of 591 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=16)]: Done 2418 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=16)]: Done 3168 tasks      | elapsed: 31.6min\n",
      "[Parallel(n_jobs=16)]: Done 4018 tasks      | elapsed: 40.0min\n",
      "[Parallel(n_jobs=16)]: Done 4968 tasks      | elapsed: 49.6min\n",
      "[Parallel(n_jobs=16)]: Done 5639 out of 5639 | elapsed: 56.3min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=16)]: Done 2418 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=16)]: Done 3168 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=16)]: Done 4018 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=16)]: Done 4968 tasks      | elapsed: 21.8min\n"
     ]
    }
   ],
   "source": [
    "vgg_repo_metric.bs_fldr = '/data/home/shruti/voxceleb/vgg/compression/'\n",
    "fab_repo_metric.bs_fldr = '/data/home/shruti/voxceleb/fabnet_metric_compression/'\n",
    "\n",
    "\n",
    "#LEADER\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'real', 10, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/ldr_real_100_onlycomp.csv')\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'fake', 10, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/ldr_fake_100_onlycomp.csv')\n",
    "\n",
    "#DFDC\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'DFDC_' in k], \n",
    "             'real', -1, \n",
    "             None, 0., 1, parallel=True)\n",
    "temp.to_pickle('result_csv/DFDC_real_100_onlycomp.csv')\n",
    "\n",
    "\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'DFDC_' in k], \n",
    "             'fake', -1, \n",
    "             None, 0., 1, parallel=True)\n",
    "temp.to_pickle('result_csv/DFDC_fake_100_onlycomp.csv')\n",
    "\n",
    "# FF\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'FF_' in k], \n",
    "             'real', -1, \n",
    "             None, 0.5, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/FF_real_100_onlycomp.csv')\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'FF_' in k], \n",
    "             'fake', -1, \n",
    "             None, 0.5, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/FF_fake_100_onlycomp.csv')\n",
    "\n",
    "\n",
    "# GG\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'GG_' in k], \n",
    "             'real', -1, \n",
    "             None, 0., 1, parallel=True)\n",
    "temp.to_pickle('result_csv/GG_real_100_onlycomp.csv')\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'GG_' in k], \n",
    "             'fake', -1, \n",
    "             None, 0., 1, parallel=True)\n",
    "temp.to_pickle('result_csv/GG_fake_100_onlycomp.csv')\n",
    "\n",
    "#Celeb-DF\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'CDF_' in k], \n",
    "             'real', -1, \n",
    "             None, 0.5, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/CDF_real_100_onlycomp.csv')\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'CDF_' in k], \n",
    "             'fake', -1, \n",
    "             None, 0.5, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/CDF_fake_100_onlycomp.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celeb-DF, GG, DFDC, Ldr, FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vgg_repo_metric.bs_fldr = '/data/home/shruti/voxceleb/vgg/compression/'\n",
    "fab_repo_metric.bs_fldr = '/data/home/shruti/voxceleb/fabnet_metric_compression/'\n",
    "\n",
    "\n",
    "#LEADER\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'real', 10, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/ldr_real_100_onlycomp.csv')\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'fake', 10, \n",
    "             None, 0, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/ldr_fake_100_onlycomp.csv')\n",
    "\n",
    "#DFDC\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'DFDC_' in k], \n",
    "             'real', -1, \n",
    "             None, 0., 1, parallel=True)\n",
    "temp.to_pickle('result_csv/DFDC_real_100_onlycomp.csv')\n",
    "\n",
    "\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'DFDC_' in k], \n",
    "             'fake', -1, \n",
    "             None, 0., 1, parallel=True)\n",
    "temp.to_pickle('result_csv/DFDC_fake_100_onlycomp.csv')\n",
    "\n",
    "# FF\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'FF_' in k], \n",
    "             'real', -1, \n",
    "             None, 0.5, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/FF_real_100_onlycomp.csv')\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'FF_' in k], \n",
    "             'fake', -1, \n",
    "             None, 0.5, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/FF_fake_100_onlycomp.csv')\n",
    "\n",
    "\n",
    "# GG\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'GG_' in k], \n",
    "             'real', -1, \n",
    "             None, 0., 1, parallel=True)\n",
    "temp.to_pickle('result_csv/GG_real_100_onlycomp.csv')\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'GG_' in k], \n",
    "             'fake', -1, \n",
    "             None, 0., 1, parallel=True)\n",
    "temp.to_pickle('result_csv/GG_fake_100_onlycomp.csv')\n",
    "\n",
    "#Celeb-DF\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'CDF_' in k], \n",
    "             'real', -1, \n",
    "             None, 0.5, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/CDF_real_100_onlycomp.csv')\n",
    "temp = save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'CDF_' in k], \n",
    "             'fake', -1, \n",
    "             None, 0.5, 1, parallel=True)\n",
    "temp.to_pickle('result_csv/CDF_fake_100_onlycomp.csv')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
