{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from test_repo_biometric import *\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the file names\n",
    "train_files, test_files = train_test_all_ids('/data/home/shruti/voxceleb/vgg/leaders/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders + ff original + imposters + Google\n",
    "def get_train_repo(params):\n",
    "    \n",
    "    out_repo = {}\n",
    "    # leaders\n",
    "    out_repo = build_repo(params['bsfldr'], \n",
    "                      {f: train_files[f] for f in ['bo','br','bs','cb','dt','ew','hc','jb','kh', 'pb',\n",
    "                                                  'bo_imposter','bs_imposter','ew_imposter','dt_imposter',\n",
    "                                                   'hc_imposter', 'jb_imposter']}, \n",
    "                      {'frames': params['frames'], 'step': params['steps'], \n",
    "                       'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                      in_dict=out_repo)\n",
    "    # ff original\n",
    "    out_repo = build_repo(params['bsfldr'], \n",
    "                  {'FF_{0:03d}'.format(f): train_files['FF_{0:03d}'.format(f)] for f in range(1000)}, \n",
    "                  {'frames': params['frames'], 'step': params['steps'], \n",
    "                   'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':0.5}, \n",
    "                  in_dict=out_repo)\n",
    "\n",
    "    # Google \n",
    "    out_repo = build_repo(params['bsfldr'], \n",
    "                  {'GG_{0:02d}'.format(f+1): train_files['GG_{0:02d}'.format(f+1)] for f in range(28)}, \n",
    "                  {'frames': params['frames'], 'step': params['steps'], \n",
    "                   'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                  in_dict=out_repo)\n",
    "    \n",
    "    # steve + jennifer\n",
    "    out_repo = build_repo(params['bsfldr'], \n",
    "                  {'steve_b': train_files['steve_b']}, \n",
    "                  {'frames': params['frames'], 'step': params['steps'], \n",
    "                   'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                  in_dict=out_repo)\n",
    "    out_repo = build_repo(params['bsfldr'], \n",
    "                  {'jen_l': train_files['jen_l']}, \n",
    "                  {'frames': params['frames'], 'step': params['steps'], \n",
    "                   'pool_func': np.mean, 'N': 5000, 'n1':0, 'n2':1}, \n",
    "                  in_dict=out_repo)\n",
    "\n",
    "    return out_repo\n",
    "\n",
    "\n",
    "def get_result_df_notime(vgg_repo, fab_repo, test_ids, r_or_f, bs_fldr1, bs_fldr2):\n",
    "    \n",
    "    out_result_df = {}\n",
    "    samples = 1\n",
    "    for ids in test_ids:\n",
    "        \n",
    "        cnt = 0\n",
    "        i = 0\n",
    "        r_or_f_res = {}\n",
    "        \n",
    "        # shuffle the files and include only till we are greater than N sample\n",
    "        cur_test_files = test_files[r_or_f][ids]\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(cur_test_files)\n",
    "        \n",
    "        while cnt<samples and i<len(cur_test_files):\n",
    "            \n",
    "            # vgg\n",
    "            vgg_test = {}\n",
    "            vgg_test = build_repo(bs_fldr1, \n",
    "                                  {ids: [cur_test_files[i]]}, \n",
    "                                  {'frames': 1, 'step': 1, \n",
    "                                   'pool_func': np.mean, 'N': -1, \n",
    "                                   'n1':0.5 if 'FF_' in ids else 0, 'n2':1}, \n",
    "                                  in_dict=vgg_test)\n",
    "            vgg_dist, vgg_pred_id = get_repo_dist(vgg_repo, vgg_test[ids])\n",
    "            \n",
    "            # fabnet\n",
    "            fab_test = {}\n",
    "            fab_test = build_repo(bs_fldr2, \n",
    "                                  {ids: [cur_test_files[i]]}, \n",
    "                                  {'frames': 1, 'step': 1, \n",
    "                                   'pool_func': np.mean, 'N': -1, \n",
    "                                   'n1':0.5 if 'FF_' in ids else 0, 'n2':1}, \n",
    "                                  in_dict=fab_test)\n",
    "            fab_dist, fab_pred_id = get_repo_dist(fab_repo, fab_test[ids])\n",
    "            \n",
    "            # same distance\n",
    "            n = np.min([len(vgg_dist), len(fab_dist)])\n",
    "            r_or_f_res[i] = pd.DataFrame(data=vgg_dist[:n], columns=['vgg_dist'])\n",
    "            r_or_f_res[i]['fab_dist'] = fab_dist[:n]\n",
    "            r_or_f_res[i]['actualLabel'] = ids\n",
    "            r_or_f_res[i]['RealFake'] = r_or_f\n",
    "            r_or_f_res[i]['filename'] = cur_test_files[i]\n",
    "            r_or_f_res[i]['vgg_pred'] = vgg_pred_id[:n]\n",
    "            r_or_f_res[i]['fab_pred'] = fab_pred_id[:n]\n",
    "            \n",
    "            i = i+1\n",
    "            cnt = cnt + n\n",
    "            print(cnt)\n",
    "            \n",
    "        out_result_df[ids] = pd.concat([r_or_f_res[f] for f in range(i)], ignore_index=True, sort=False)\n",
    "        \n",
    "    return pd.concat([out_result_df[f] for f in test_ids], ignore_index=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_repo = get_train_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':1, 'steps':1})\n",
    "\n",
    "fab_repo = get_train_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet/leaders/', \n",
    "                                'frames':1, 'steps':1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632\n",
      "1280\n",
      "1053\n",
      "322\n",
      "420\n",
      "325\n",
      "1483\n",
      "1757\n",
      "824\n",
      "667\n",
      "238\n",
      "276\n",
      "347\n",
      "182\n",
      "186\n",
      "231\n",
      "155\n",
      "303\n",
      "382\n",
      "294\n",
      "285\n",
      "395\n",
      "218\n",
      "199\n",
      "338\n",
      "219\n",
      "339\n",
      "199\n",
      "216\n",
      "693\n",
      "234\n",
      "216\n",
      "163\n",
      "332\n",
      "184\n",
      "374\n",
      "193\n",
      "158\n",
      "217\n",
      "250\n",
      "149\n",
      "241\n",
      "155\n",
      "486\n",
      "204\n",
      "254\n",
      "202\n",
      "273\n",
      "153\n",
      "305\n",
      "329\n",
      "210\n",
      "338\n",
      "248\n",
      "168\n",
      "210\n",
      "252\n",
      "160\n",
      "291\n",
      "180\n",
      "318\n",
      "430\n",
      "162\n",
      "250\n",
      "184\n",
      "197\n"
     ]
    }
   ],
   "source": [
    "\n",
    "real_df = get_result_df_notime(vgg_repo, fab_repo, \n",
    "                               list(test_files['real'].keys()), 'real', \n",
    "                               '/data/home/shruti/voxceleb/vgg/leaders/',\n",
    "                              '/data/home/shruti/voxceleb/fabnet/leaders/')\n",
    "fake_df = get_result_df_notime(vgg_repo, fab_repo, list(test_files['fake'].keys()), 'fake', \n",
    "                               '/data/home/shruti/voxceleb/vgg/leaders/',\n",
    "                              '/data/home/shruti/voxceleb/fabnet/leaders/')\n",
    "\n",
    "full_df = pd.concat([real_df, fake_df], ignore_index=True, sort=False)\n",
    "\n",
    "full_df.to_csv('results1_vggfab.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressed Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders\n",
    "real_df_comp = get_result_df_notime(vgg_repo, fab_repo, \n",
    "                                    list(test_files['real'].keys()), 'real', \n",
    "                                    '/data/home/shruti/voxceleb/vgg/compression/',\n",
    "                                    '/data/home/shruti/voxceleb/fabnet/compression/')\n",
    "fake_df_comp = get_result_df_notime(vgg_repo, fab_repo, \n",
    "                                    list(test_files['fake'].keys()), 'fake', \n",
    "                                    '/data/home/shruti/voxceleb/vgg/compression/',\n",
    "                                    '/data/home/shruti/voxceleb/fabnet/compression/')\n",
    "\n",
    "vgg_results_comp.to_csv('results1_vggfab_comp.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with only leaders in repository\n",
    "# if we had leaders in the repo and we get the face-swap of leaders dist\n",
    "# how we do on Leader Faceswap\n",
    "def get_auc(in_result_df, real_nm, fake_nm):\n",
    "    \n",
    "    real_dist = in_result_df.loc[np.logical_and(in_result_df['actualLabel'].isin(real_nm), \n",
    "                                                in_result_df['RealFake']=='real'), 'dist']\n",
    "    \n",
    "    fake_dist = in_result_df.loc[np.logical_and(in_result_df['actualLabel'].isin(fake_nm), \n",
    "                                                in_result_df['RealFake']=='fake'), 'dist']\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(np.concatenate((np.ones((len(real_dist), )), \n",
    "                                                    np.zeros((len(fake_dist), )) )), \n",
    "                                     np.concatenate((real_dist, \n",
    "                                                     fake_dist)))\n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "def get_dis_accuracy(df2, real_nm, fake_nm):\n",
    "    \n",
    "    # real accuracy\n",
    "    r1 = df2.loc[np.logical_and(df2['actualLabel'].isin(real_nm), \n",
    "                                df2['RealFake']=='real'), 'actualLabel']\n",
    "    r2 = df2.loc[np.logical_and(df2['actualLabel'].isin(real_nm), \n",
    "                                df2['RealFake']=='real'), 'predLabel']\n",
    "    real_acc = len(np.argwhere(r1 == r2).ravel())/len(r1)\n",
    "    \n",
    "    # fake accuracy\n",
    "    f1 = df2.loc[np.logical_and(df2['actualLabel'].isin(fake_nm), \n",
    "                                df2['RealFake']=='fake'), 'actualLabel']\n",
    "    f2 = df2.loc[np.logical_and(df2['actualLabel'].isin(fake_nm), \n",
    "                                df2['RealFake']=='fake'), 'predLabel']\n",
    "    fake_acc = len(np.argwhere(f1 != f2).ravel())/len(f1)\n",
    "    \n",
    "    return real_acc, fake_acc\n",
    "\n",
    "\n",
    "def get_four_measures(cur_df1, cur_df2):\n",
    "    \n",
    "    out_res = np.zeros((2, 4))\n",
    "    out_res[0, 0] = len(np.argwhere((np.array(cur_df1['predLabel']) == np.array(cur_df2['predLabel']))\n",
    "                    & (np.array(cur_df2['predLabel']) == np.array(cur_df2['actualLabel']))).ravel())\n",
    "    \n",
    "    out_res[0, 1] = len(np.argwhere((np.array(cur_df1['predLabel']) == np.array(cur_df2['predLabel'])) \n",
    "                                    & (np.array(cur_df2['predLabel']) != np.array(cur_df2['actualLabel'])) \n",
    "                                    & (np.array(cur_df1['predLabel']) != np.array(cur_df1['actualLabel']))).ravel())\n",
    "    \n",
    "    out_res[1, 1] = len(np.argwhere((np.array(cur_df1['predLabel']) != np.array(cur_df2['predLabel'])) \n",
    "                                    & (np.array(cur_df2['predLabel']) != np.array(cur_df2['actualLabel'])) \n",
    "                                    & (np.array(cur_df1['predLabel']) != np.array(cur_df1['actualLabel']))).ravel())\n",
    "    \n",
    "    \n",
    "    out_res[1, 2] = len(np.argwhere((np.array(cur_df1['predLabel']) != np.array(cur_df2['predLabel'])) \n",
    "                                & (np.array(cur_df2['predLabel']) != np.array(cur_df2['actualLabel'])) \n",
    "                                & (np.array(cur_df1['predLabel']) == np.array(cur_df1['actualLabel']))).ravel())\n",
    "    \n",
    "    out_res[1, 3] = len(np.argwhere((np.array(cur_df1['predLabel']) != np.array(cur_df2['predLabel'])) \n",
    "                            & (np.array(cur_df2['predLabel']) == np.array(cur_df2['actualLabel'])) \n",
    "                            & (np.array(cur_df1['predLabel']) != np.array(cur_df1['actualLabel']))).ravel())\n",
    "    \n",
    "    return out_res\n",
    "\n",
    "\n",
    "def get_discrepany_accuracy(df1, df2, real_nm, fake_nm):\n",
    "    \n",
    "    out_result = {}\n",
    "    # true label\n",
    "    out_result['real'] = np.zeros((2, 4)) # pred values (real,fake), (VGG_c-Fab_c, VGG_i-Fab_i, VGG_c-Fab_i, VGG_i-Fab_c)\n",
    "    out_result['fake'] = np.zeros((2, 4))\n",
    "    \n",
    "    # real accuracy df1\n",
    "    for k in real_nm:\n",
    "        \n",
    "        cur_df1 = df1[(df1['actualLabel']==k) & (df1['RealFake']=='real')]\n",
    "        cur_df2 = df2[(df2['actualLabel']==k) & (df2['RealFake']=='real')]\n",
    "        n = np.min([len(cur_df1), len(cur_df2)])\n",
    "        cur_df1 = cur_df1.iloc[:n, :].copy()\n",
    "        cur_df2 = cur_df2.iloc[:n, :].copy()\n",
    "        \n",
    "        # real prediction count\n",
    "        out_result['real'] = out_result['real'] + get_four_measures(cur_df1, cur_df2)\n",
    "    \n",
    "    for k in fake_nm:\n",
    "        \n",
    "        cur_df1 = df1[(df1['actualLabel']==k) & (df1['RealFake']=='fake')]\n",
    "        cur_df2 = df2[(df2['actualLabel']==k) & (df2['RealFake']=='fake')]\n",
    "        n = np.min([len(cur_df1), len(cur_df2)])\n",
    "        cur_df1 = cur_df1.iloc[:n, :].copy()\n",
    "        cur_df2 = cur_df2.iloc[:n, :].copy()\n",
    "        \n",
    "        # real prediction count\n",
    "        out_result['fake'] = out_result['fake'] + get_four_measures(cur_df1, cur_df2)\n",
    "            \n",
    "    return out_result\n",
    "    \n",
    "    \n",
    "def plot_dist(in_result_df, real_nm, fake_nm, ax, title):\n",
    "    \n",
    "    sns.distplot(np.log(in_result_df.loc[np.logical_and(in_result_df['actualLabel'].isin(real_nm), \n",
    "                                                in_result_df['RealFake']=='real'), 'dist']), \n",
    "                 bins=np.log(np.linspace(0.1, 1, 30)), label='real', ax=ax)\n",
    "    sns.distplot(np.log(in_result_df.loc[np.logical_and(in_result_df['actualLabel'].isin(fake_nm), \n",
    "                                                in_result_df['RealFake']=='fake'), 'dist']), \n",
    "                 bins=np.log(np.linspace(0.1, 1, 30)), label='fake', ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim([np.log(0.1), np.log(1)])\n",
    "    ax.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrepancy Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(in_res_o):\n",
    "    \n",
    "    in_res = {}\n",
    "    in_res['real'] = in_res_o['real']*100/np.sum(in_res_o['real'])\n",
    "    in_res['fake'] = in_res_o['fake']*100/np.sum(in_res_o['fake'])\n",
    "    print('\\t True Positve: {0:3.2f} True Negative: {1:3.2f}\\n'.format(in_res['real'][0,0], \n",
    "                                                                    in_res['fake'][1,2]+\n",
    "                                                                    in_res['fake'][1,1]+\n",
    "                                                                    in_res['fake'][1,3]))\n",
    "    print('\\t \\t VGG_c-Fab_c \\t VGG_i-Fab_i \\t VGG_c-Fab_i \\t VGG_i-Fab_c \\n')\n",
    "    print('Real->Real \\t {0:3.2f} \\t\\t {1:3.2f} \\t\\t {2:3.2f} \\t\\t {3:3.2f} \\n'.format(in_res['real'][0, 0],\n",
    "                                                                               in_res['real'][0, 1],\n",
    "                                                                               in_res['real'][0, 2],\n",
    "                                                                               in_res['real'][0, 3]))\n",
    "    print('Real->Fake \\t {0:3.2f} \\t\\t {1:3.2f} \\t\\t {2:3.2f} \\t\\t {3:3.2f} \\n'.format(in_res['real'][1, 0],\n",
    "                                                                               in_res['real'][1, 1],\n",
    "                                                                               in_res['real'][1, 2],\n",
    "                                                                               in_res['real'][1, 3]))\n",
    "    print('Fake->Real \\t {0:3.2f} \\t\\t {1:3.2f} \\t\\t {2:3.2f} \\t\\t {3:3.2f} \\n'.format(in_res['fake'][0, 0],\n",
    "                                                                               in_res['fake'][0, 1],\n",
    "                                                                               in_res['fake'][0, 2],\n",
    "                                                                               in_res['fake'][0, 3]))\n",
    "    print('Fake->Fake \\t {0:3.2f} \\t\\t {1:3.2f} \\t\\t {2:3.2f} \\t\\t {3:3.2f} \\n'.format(in_res['fake'][1, 0],\n",
    "                                                                               in_res['fake'][1, 1],\n",
    "                                                                               in_res['fake'][1, 2],\n",
    "                                                                               in_res['fake'][1, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (VGG + Fabnet Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Leaders + FF original + Imposters + Google \\n')\n",
    "\n",
    "print('\\t Leaders \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_repo4, fabnet_repo4,\n",
    "                                     ['bo','bs','dt','ew','hc','jb'], \n",
    "                                     ['bo','bs','dt','ew','hc','jb']))\n",
    "print('\\t FaceForensics \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_repo4, fabnet_repo4,\n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)]))\n",
    "print('\\t Google \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_repo4, fabnet_repo4,\n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)]))\n",
    "print('\\t ALL \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_repo4, fabnet_repo4,\n",
    "                        test_files['real'].keys(), \n",
    "                        test_files['fake'].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Time (VGG + Fabnet Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t Leaders \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_1, fabnet_results_1,\n",
    "                                     ['bo','bs','dt','ew','hc','jb'], \n",
    "                                     ['bo','bs','dt','ew','hc','jb']))\n",
    "print('\\t FaceForensics \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_1, fabnet_results_1,\n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)]))\n",
    "print('\\t Google \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_1, fabnet_results_1,\n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)]))\n",
    "print('\\t ALL \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_1, fabnet_results_1,\n",
    "                        test_files['real'].keys(), \n",
    "                        test_files['fake'].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('\\t Leaders \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_comp, fabnet_results_comp,\n",
    "                                     ['bo','bs','dt','ew','hc','jb'], \n",
    "                                     ['bo','bs','dt','ew','hc','jb']))\n",
    "\"\"\"print('\\t FaceForensics \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_comp, fabnet_results_comp,\n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)]))\n",
    "print('\\t Google \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_comp, fabnet_results_comp,\n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)]))\n",
    "print('\\t ALL \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_comp, fabnet_results_comp,\n",
    "                        test_files['real'].keys(), \n",
    "                        test_files['fake'].keys()))\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25 VGG + Fabnet Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Leaders + FF original + Imposters + Google \\n')\n",
    "\n",
    "print('\\t Leaders \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_25, fabnet_results_25,\n",
    "                                     ['bo','bs','dt','ew','hc','jb'], \n",
    "                                     ['bo','bs','dt','ew','hc','jb']))\n",
    "print('\\t FaceForensics \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_25, fabnet_results_25,\n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)]))\n",
    "print('\\t Google \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_25, fabnet_results_25,\n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)]))\n",
    "print('\\t ALL \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_25, fabnet_results_25,\n",
    "                        test_files['real'].keys(), \n",
    "                        test_files['fake'].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 VGG + Fabnet Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Leaders + FF original + Imposters + Google \\n')\n",
    "\n",
    "print('\\t Leaders \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_50, fabnet_results_50,\n",
    "                                     ['bo','bs','dt','ew','hc','jb'], \n",
    "                                     ['bo','bs','dt','ew','hc','jb']))\n",
    "print('\\t FaceForensics \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_50, fabnet_results_50,\n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)]))\n",
    "print('\\t Google \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_50, fabnet_results_50,\n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)]))\n",
    "print('\\t ALL \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_50, fabnet_results_50,\n",
    "                        test_files['real'].keys(), \n",
    "                        test_files['fake'].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75 VGG + Fabnet Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Leaders + FF original + Imposters + Google \\n')\n",
    "\n",
    "print('\\t Leaders \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_75, fabnet_results_75,\n",
    "                                     ['bo','bs','dt','ew','hc','jb'], \n",
    "                                     ['bo','bs','dt','ew','hc','jb']))\n",
    "print('\\t FaceForensics \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_75, fabnet_results_75,\n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                        ['FF_{0:03d}'.format(f) for f in range(1000)]))\n",
    "print('\\t Google \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_75, fabnet_results_75,\n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                        ['GG_{0:02d}'.format(f+1) for f in range(28)]))\n",
    "print('\\t ALL \\n ')\n",
    "print_result(get_discrepany_accuracy(vgg_results_75, fabnet_results_75,\n",
    "                        test_files['real'].keys(), \n",
    "                        test_files['fake'].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Only Leaders')\n",
    "print('\\t VGG')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(vgg_repo1, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t Fabnet Metric')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(fabnet_repo1, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "\n",
    "print('Repo Leaders + FF original')\n",
    "print('\\t VGG')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(vgg_repo2, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics {0:0.4f}'.format(get_auc(vgg_repo2, \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "print('\\t Fabnet Metric')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(fabnet_repo2, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics {0:0.4f}'.format(get_auc(fabnet_repo2, \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "\n",
    "\n",
    "print('Repo Leaders + FF original + Imposters')\n",
    "print('\\t VGG')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(vgg_repo3, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics {0:0.4f}'.format(get_auc(vgg_repo3, \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "print('\\t Fabnet Metric')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(fabnet_repo3, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics {0:0.4f}'.format(get_auc(fabnet_repo3, \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Leaders + FF original + Imposters + Google')\n",
    "print('\\t VGG')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(vgg_repo4, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics {0:0.4f}'.format(get_auc(vgg_repo4, \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "print('\\t \\t Google {0:0.4f}'.format(get_auc(vgg_repo4, \n",
    "                                              ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                                              ['GG_{0:02d}'.format(f+1) for f in range(28)])))\n",
    "\n",
    "\n",
    "print('\\t Fabnet Metric')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(fabnet_repo4, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics {0:0.4f}'.format(get_auc(fabnet_repo4, \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "print('\\t \\t Google {0:0.4f}'.format(get_auc(fabnet_repo4, \n",
    "                                              ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                                              ['GG_{0:02d}'.format(f+1) for f in range(28)])))\n",
    "\n",
    "print('\\t Fabnet Pool')\n",
    "print('\\t \\t leaders {0:0.4f}'.format(get_auc(fabnetPool_repo4, \n",
    "                                              ['bo','bs','dt','ew','hc','jb'], \n",
    "                                              ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics {0:0.4f}'.format(get_auc(fabnetPool_repo4, \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                              ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "print('\\t \\t Google {0:0.4f}'.format(get_auc(fabnetPool_repo4, \n",
    "                                              ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                                              ['GG_{0:02d}'.format(f+1) for f in range(28)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Only Leaders')\n",
    "print('\\t \\t leaders (real, fake) {}'.format(get_dis_accuracy(vgg_repo1, fabnet_repo1,\n",
    "                                                       ['bo','bs','dt','ew','hc','jb'], \n",
    "                                                       ['bo','bs','dt','ew','hc','jb'])))\n",
    "\n",
    "print('Repo Leaders + FF original')\n",
    "print('\\t \\t leaders (real, fake) {}'.format(get_dis_accuracy(vgg_repo2, fabnet_repo2,\n",
    "                                                       ['bo','bs','dt','ew','hc','jb'], \n",
    "                                                       ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics (real, fake) {}'.format(get_dis_accuracy(vgg_repo2, fabnet_repo2,\n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "\n",
    "print('Repo Leaders + FF original + Imposter')\n",
    "print('\\t \\t leaders (real, fake) {}'.format(get_dis_accuracy(vgg_repo3, fabnet_repo3,\n",
    "                                                       ['bo','bs','dt','ew','hc','jb'], \n",
    "                                                       ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics (real, fake) {}'.format(get_dis_accuracy(vgg_repo3, fabnet_repo3,\n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "\n",
    "\n",
    "print('Repo Leaders + FF original + Imposters + Google')\n",
    "print('\\t \\t leaders (real, fake) {}'.format(get_dis_accuracy(vgg_repo4, fabnet_repo4,\n",
    "                                                       ['bo','bs','dt','ew','hc','jb'], \n",
    "                                                       ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics (real, fake) {}'.format(get_dis_accuracy(vgg_repo4, fabnet_repo4,\n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "print('\\t \\t Google (real, fake) {}'.format(get_dis_accuracy(vgg_repo4, fabnet_repo4,\n",
    "                                                             ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                                                             ['GG_{0:02d}'.format(f+1) for f in range(28)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repo Leaders + FF original + Imposters + Google')\n",
    "print('\\t \\t leaders (real, fake) {}'.format(get_dis_accuracy(fabnet_repo4,\n",
    "                                                       ['bo','bs','dt','ew','hc','jb'], \n",
    "                                                       ['bo','bs','dt','ew','hc','jb'])))\n",
    "print('\\t \\t FaceForensics (real, fake) {}'.format(get_dis_accuracy(fabnet_repo4,\n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                                                             ['FF_{0:03d}'.format(f) for f in range(1000)])))\n",
    "print('\\t \\t Google (real, fake) {}'.format(get_dis_accuracy(fabnet_repo4,\n",
    "                                                             ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                                                             ['GG_{0:02d}'.format(f+1) for f in range(28)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC\n",
    "\n",
    "|                |Only  Leaders|| Leaders + FaceForensics|| Leaders + FaceForensics + Imposter || \n",
    "|----------------|-----|--------|------------|------------|----------------|--------------------|\n",
    "|                |VGG  | Fabnet |     VGG    |   Fabnet   |     VGG        |     Fabnet         |\n",
    "|                |     |        |            |            |                |                    |\n",
    "|Leaders         |88.6 | 93.3   |    88.6    |    92.7    |      87.9      |         28.7       |\n",
    "|Face Forensics  |NA   | NA     |    99.7    |    98.2    |      99.7      |         98.2       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCURACY\n",
    "\n",
    "|                |Only  Leaders|| Leaders + FaceForensics|| Leaders + FaceForensics + Imposter || \n",
    "|----------------|-------------|--------------|--------------|--------------|--------------|--------------|\n",
    "|                |True Positive| True Negative| True Positive| True Negative| True Positive|True Negative |\n",
    "|                |             |              |              |              |              |              |\n",
    "|Leaders         |99.4         | 26.6         |    98.9      |    39.9      |     97.5     |    99.2      |\n",
    "|Face Forensics  |NA           | NA           |    99.4      |    97.1      |     99.4     |    97.2      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(10,14))\n",
    "\n",
    "plot_dist(vgg_repo4, ['bo','bs','dt','ew','hc','jb'], \n",
    "          ['bo','bs','dt','ew','hc','jb'], \n",
    "          ax[0, 0], 'VGG: Leaders')\n",
    "plot_dist(vgg_repo4, ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "          ['FF_{0:03d}'.format(f) for f in range(1000)], ax[1, 0], \n",
    "          'VGG: FaceForensics')\n",
    "plot_dist(vgg_repo4, ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "          ['GG_{0:02d}'.format(f+1) for f in range(28)], ax[2, 0], \n",
    "          'VGG: Google')\n",
    "\n",
    "plot_dist(fabnet_repo4, ['bo','bs','dt','ew','hc','jb'], \n",
    "          ['bo','bs','dt','ew','hc','jb'], \n",
    "          ax[0, 1], 'Fabnet: Leaders')\n",
    "plot_dist(fabnet_repo4, ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "          ['FF_{0:03d}'.format(f) for f in range(1000)], ax[1, 1], \n",
    "          'Fabnet: FaceForensics')\n",
    "plot_dist(fabnet_repo4, ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "          ['GG_{0:02d}'.format(f+1) for f in range(28)], ax[2, 1], \n",
    "          'Fabnet: Google')\n",
    "plt.subplots_adjust(hspace=0.3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
