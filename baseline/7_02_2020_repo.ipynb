{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from repo import *\n",
    "import utils as u\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before 4105\n",
      "after 3739\n"
     ]
    }
   ],
   "source": [
    "# get the file names\n",
    "train_files, test_files = u.train_test_all_ids('/data/home/shruti/voxceleb/vgg/leaders/')\n",
    "all_lbls = list(train_files.keys())\n",
    "all_lbls.sort()\n",
    "all_lbls = np.array(all_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders + ff original + imposters + Google\n",
    "def get_train_repo(params):\n",
    "    \n",
    "    out_repo = Repo(params['bsfldr'], params['frames'], params['steps'], np.mean, 5000)\n",
    "    out_repo.add_ids({f: train_files[f] for f in ['bo','br','bs','cb','dt','ew','hc','jb','kh', 'pb',\n",
    "                                                  'bo_imposter','bs_imposter','ew_imposter','dt_imposter',\n",
    "                                                   'hc_imposter', 'jb_imposter']}, 0, 1)\n",
    "    out_repo.add_ids({f: train_files[f] for f in train_files.keys() if 'FF_' in f}, 0, 0.5)\n",
    "    out_repo.add_ids({f: train_files[f] for f in train_files.keys() if 'GG_' in f}, 0, 1)\n",
    "    out_repo.add_ids({'steve_b': train_files['steve_b']}, 0, 1)\n",
    "    out_repo.add_ids({'jen_l': train_files['jen_l']}, 0, 1)\n",
    "    \n",
    "    # get dfdc dataset id\n",
    "    out_repo.add_ids({k: train_files[k] for k in train_files.keys() if 'DFDC_' in k}, 0, 1)\n",
    "    out_repo.build_repo_noKDD()\n",
    "    \n",
    "    return out_repo\n",
    "\n",
    "\n",
    "def save_results(vgg_repo, fab_repo, test_ids, r_or_f, N_f, out_file, n1, n2, parallel=False):\n",
    "        \n",
    "    # number of files per id\n",
    "    test_dict = {}\n",
    "    for ids in test_ids:\n",
    "        cur_test_files = test_files[r_or_f][ids]\n",
    "        if N_f>0 and len(cur_test_files)>N_f:\n",
    "            test_dict[ids] = cur_test_files[:N_f].copy()\n",
    "        else:\n",
    "            test_dict[ids] = cur_test_files.copy()\n",
    "            \n",
    "    vgg_result = vgg_repo.dist_using_dict(test_dict, n1, n2, parallel=parallel, dist='cosine')\n",
    "    vgg_result['RealFake'] = r_or_f\n",
    "    fab_result = fab_repo.dist_using_dict(test_dict, n1, n2, parallel=parallel, dist='cosine')\n",
    "    fab_result['RealFake'] = r_or_f\n",
    "    full_df = vgg_result.set_index('fileName').join(fab_result.set_index('fileName'), \n",
    "                                                 how='inner', lsuffix='_vgg', rsuffix='_fab')\n",
    "    full_df = full_df[['predLabel_vgg', 'actualLabel_vgg', \n",
    "                       'RealFake_vgg', 'predLabel_fab', 'dist_vgg', 'dist_fab']].copy()\n",
    "    \n",
    "    if out_file is not None:\n",
    "        full_df.to_csv(out_file)\n",
    "        \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_repo = get_train_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':1, 'steps':5, 'N_comp':512})\n",
    "\n",
    "fab_repo = get_train_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet/leaders/', \n",
    "                                'frames':1, 'steps':5, 'N_comp':-1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(vgg_repo, fab_repo, \n",
    "             ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "             'real', -1, \n",
    "             'result_csv/FF_real_notime.csv', 0.5, 1, parallel=True)\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "             'fake', -1, \n",
    "             'result_csv/FF_fake_notime.csv', 0.5, 1, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the location of the base folder in the repo\n",
    "vgg_repo.bs_fldr = '/data/home/shruti/voxceleb/vgg/leaders/'\n",
    "fab_repo.bs_fldr = '/data/home/shruti/voxceleb/fabnet/leaders/'\n",
    "\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "             'real', -1, \n",
    "             'result_csv/GG_real_notime.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "             'fake', -1, \n",
    "             'result_csv/GG_fake_notime.csv', 0, 1, parallel=True)\n",
    "\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'real', 10, \n",
    "             'result_csv/ldr_real_notime.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'fake', 10, \n",
    "             'result_csv/ldr_fake_notime.csv', 0, 1, parallel=True)\n",
    "\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['jen_l'], \n",
    "             'real', -1, \n",
    "             'result_csv/SJ_real_notime.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['steve_b'], \n",
    "             'fake', -1, \n",
    "             'result_csv/SJ_fake_notime.csv', 0, 1, parallel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv('result_csv/GG_real_notime.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('result_csv/GG_fake_notime.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv('result_csv/ldr_real_notime.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('result_csv/ldr_fake_notime.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv('result_csv/FF_real_notime.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('result_csv/FF_fake_notime.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv('result_csv/SJ_real_notime.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('result_csv/SJ_fake_notime.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressed Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the location of the base folder in the repo\n",
    "vgg_repo.bs_fldr = '/data/home/shruti/voxceleb/vgg/compression/'\n",
    "fab_repo.bs_fldr = '/data/home/shruti/voxceleb/fabnet/compression/'\n",
    "\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'real', 10, \n",
    "             'result_csv/ldr_real_notime_comp.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'fake', 10, \n",
    "             'result_csv/ldr_fake_notime_comp.csv', 0, 1, parallel=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/opt/voxceleb/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-937ca675b52f>\", line 2, in <module>\n",
      "    'frames':100, 'steps':5, 'N_comp':512})\n",
      "  File \"<ipython-input-5-3035594aab83>\", line 8, in get_train_repo\n",
      "    out_repo.add_ids({f: train_files[f] for f in train_files.keys() if 'FF_' in f}, 0, 0.5)\n",
      "  File \"/data/home/shruti/voxceleb/motion_signature/baseline/repo.py\", line 115, in add_ids\n",
      "    self.emb = np.concatenate((self.emb, all_id_feat), axis=0)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/opt/voxceleb/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/opt/voxceleb/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/data/opt/voxceleb/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/data/opt/voxceleb/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/usr/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "vgg_repo_metric = get_train_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':100, 'steps':5, 'N_comp':512})\n",
    "fab_repo_metric = get_train_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric/', \n",
    "                                'frames':1, 'steps':1, 'N_comp':-1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_repo_metric.bs_fldr = '/data/home/shruti/voxceleb/vgg/leaders/'\n",
    "fab_repo_metric.bs_fldr = '/data/home/shruti/voxceleb/fabnet_metric/'\n",
    "\n",
    "\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'DFDC_' in k], \n",
    "             'real', -1, \n",
    "             'result_csv/DFDC_real_100.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'DFDC_' in k], \n",
    "             'fake', -1, \n",
    "             'result_csv/DFDC_fake_100.csv', 0, 1, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv('result_csv/DFDC_real_100.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('result_csv/DFDC_fake_100.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'real', 10, \n",
    "             'result_csv/ldr_real_100.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'fake', 10, \n",
    "             'result_csv/ldr_fake_100.csv', 0, 1, parallel=True)\n",
    "\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'FF_' in k], \n",
    "             'real', -1, \n",
    "             'result_csv/FF_real_100.csv', 0.5, 1, parallel=True)\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'FF_' in k], \n",
    "             'fake', -1, \n",
    "             'result_csv/FF_fake_100.csv', 0.5, 1, parallel=True)\n",
    "\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'GG_' in k], \n",
    "             'real', -1, \n",
    "             'result_csv/GG_real_100.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'GG_' in k], \n",
    "             'fake', -1, \n",
    "             'result_csv/GG_fake_100.csv', 0, 1, parallel=True)\n",
    "\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['jen_l'], \n",
    "             'real', -1, \n",
    "             'result_csv/SJ_real_100.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['steve_b'], \n",
    "             'fake', -1, \n",
    "             'result_csv/SJ_fake_100.csv', 0, 1, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "real_df = pd.read_csv('result_csv/ldr_real_100.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('result_csv/ldr_fake_100.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))\n",
    "\n",
    "\n",
    "real_df = pd.read_csv('result_csv/GG_real_100.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('result_csv/GG_fake_100.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "real_df = pd.read_csv('result_csv/FF_real_100.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('result_csv/FF_fake_100.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv('result_csv/SJ_real_100.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('result_csv/SJ_fake_100.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressed Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_repo_metric.bs_fldr = '/data/home/shruti/voxceleb/vgg/compression/'\n",
    "fab_repo_metric.bs_fldr = '/data/home/shruti/voxceleb/fabnet_metric_compression/'\n",
    "\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'real', 10, \n",
    "             'result_csv/ldr_real_100_comp.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'fake', 10, \n",
    "             'result_csv/ldr_fake_100_comp.csv', 0, 1, parallel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['real'].keys() if 'FF_' in k], \n",
    "             'real', -1, \n",
    "             'result_csv/FF_real_100_comp.csv', 0.5, 1, parallel=True)\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             [k for k in test_files['fake'].keys() if 'FF_' in k], \n",
    "             'fake', -1, \n",
    "             'result_csv/FF_fake_100_comp.csv', 0.5, 1, parallel=True)\n",
    "\n",
    "\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['jen_l'], \n",
    "             'real', -1, \n",
    "             'result_csv/SJ_real_100_comp.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['steve_b'], \n",
    "             'fake', -1, \n",
    "             'result_csv/SJ_fake_100_comp.csv', 0, 1, parallel=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# file ablation for jennifer example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of real video of length 3 minutes of Jennifer as a function of number of frames in repo for the Jennifer similar video\n",
    "\n",
    "Also, test with close video being added to rest of the videos, or only the close video is used in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo with leaders + ff original + imposters + Google\n",
    "def build_first_repo(params):\n",
    "    \n",
    "    out_repo = Repo(params['bsfldr'], params['frames'], params['steps'], np.mean, 5000)\n",
    "    out_repo.add_ids({f: train_files[f] for f in ['bo','br','bs','cb','dt','ew','hc','jb','kh', 'pb',\n",
    "                                                  'bo_imposter','bs_imposter','ew_imposter','dt_imposter',\n",
    "                                                   'hc_imposter', 'jb_imposter']}, 0, 1)\n",
    "    out_repo.add_ids({'FF_{0:03d}'.format(f): train_files['FF_{0:03d}'.format(f)] for f in range(1000)}, 0, 0.5)\n",
    "    out_repo.add_ids({'GG_{0:02d}'.format(f+1): train_files['GG_{0:02d}'.format(f+1)] for f in range(28)}, 0, 1)\n",
    "    out_repo.add_ids({'steve_b': train_files['steve_b']}, 0, 1)\n",
    "    \n",
    "    return out_repo\n",
    "\n",
    "def jennifer_ablation(out_repo, perc, both=False):\n",
    "    out_repo.remove_ids(['jen_l'])\n",
    "    \n",
    "    if perc == 0 or both:\n",
    "        out_repo.add_ids({'jen_l': [f for f in train_files['jen_l'] if 'pW7TbJJMVak' not in f]}, 0, 1)\n",
    "    if perc > 0:\n",
    "        out_repo.add_ids({'jen_l': ['jennifer_l/pW7TbJJMVak_0.npy']}, 0, perc)\n",
    "        \n",
    "    out_repo.build_repo_noKDD()\n",
    "\n",
    "def run_one_case(vgg_repo, fab_repo, perc, both=False):\n",
    "    \n",
    "    jennifer_ablation(vgg_repo, perc, both)\n",
    "    jennifer_ablation(fab_repo, perc, both)\n",
    "    \n",
    "    real_df = save_results(vgg_repo, fab_repo, ['jen_l'], 'real', -1, None, 0, 1, parallel=True)\n",
    "    fake_df = save_results(vgg_repo, fab_repo, ['steve_b'], 'fake', -1, None, 0, 1, parallel=True)\n",
    "    \n",
    "    real_acc = len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df)\n",
    "    fake_acc = len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df)\n",
    "    \n",
    "    return real_acc, fake_acc\n",
    "\n",
    "\n",
    "def jennifer_file_ablation(out_repo, file):\n",
    "    out_repo.remove_ids(['jen_l'])\n",
    "    out_repo.add_ids({'jen_l': file}, 0, 1)\n",
    "    out_repo.build_repo_noKDD()\n",
    "    \n",
    "    \n",
    "def run_one_file_ablation_case(vgg_repo, fab_repo, file):\n",
    "    \n",
    "    jennifer_file_ablation(vgg_repo, file)\n",
    "    jennifer_file_ablation(fab_repo, file)\n",
    "    \n",
    "    real_df = save_results(vgg_repo, fab_repo, ['jen_l'], 'real', -1, None, 0, 1, parallel=True)\n",
    "    fake_df = save_results(vgg_repo, fab_repo, ['steve_b'], 'fake', -1, None, 0, 1, parallel=True)\n",
    "    \n",
    "    real_acc = len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df)\n",
    "    fake_acc = len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df)\n",
    "    \n",
    "    return real_acc, fake_acc\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_repo = build_first_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':100, 'steps':5, 'N_comp':512})\n",
    "fab_repo = build_first_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric/', \n",
    "                                'frames':1, 'steps':1, 'N_comp':-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jennifer_ablation(vgg_repo, 0, both=False)\n",
    "jennifer_ablation(fab_repo, 0, both=False)\n",
    "\n",
    "real_df = save_results(vgg_repo, fab_repo, ['jen_l'], 'real', -1, 'result_csv/SJ_real_100_onlyother.csv', 0, 1, parallel=True)\n",
    "fake_df = save_results(vgg_repo, fab_repo, ['steve_b'], 'fake', -1, 'result_csv/SJ_fake_100_onlyother.csv', 0, 1, parallel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Case1 only other videos\n",
    "r1, f1 = run_one_case(vgg_repo, fab_repo, 0, both=False)\n",
    "\n",
    "#Case2 other videos with 3 minutes new video\n",
    "r2, f2 = run_one_case(vgg_repo, fab_repo, 1, both=False)\n",
    "\n",
    "#Case3 only overlapping video with diff perc\n",
    "p_rng = np.linspace(0.03, 1, 10)\n",
    "r_f3 = np.zeros((len(p_rng), 3))\n",
    "for i in range(len(p_rng)):\n",
    "    r_f3[i, 0] = 3*60*p_rng[i] # these many seconds\n",
    "    r_f3[i, 1:] = run_one_case(vgg_repo, fab_repo, p_rng[i], both=False)\n",
    "\n",
    "#Case4 both videos with diff perc\n",
    "r_f4 = np.zeros((len(p_rng), 3))\n",
    "for i in range(len(p_rng)):\n",
    "    r_f4[i, 0] = 3*60*p_rng[i] # these many seconds\n",
    "    r_f4[i, 1:] = run_one_case(vgg_repo, fab_repo, p_rng[i], both=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "files_jen = np.unique([f.split('/')[-1].split('_')[0] for f in train_files['jen_l']])\n",
    "print(files_jen)\n",
    "\n",
    "acc = np.zeros((len(files_jen), 2))\n",
    "for i in range(len(files_jen)):\n",
    "    \n",
    "    cur_files = [f for f in train_files['jen_l'] if files_jen[i] in f]\n",
    "    acc[i, :] = run_one_file_ablation_case(vgg_repo, fab_repo, cur_files)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data = acc, columns=['real_acc', 'fake_acc'])\n",
    "result_df['filename'] = files_jen\n",
    "result_df['avg_acc'] = (np.array(result_df['real_acc']) + np.array(1-result_df['fake_acc']))/2\n",
    "\n",
    "display(result_df.sort_values('avg_acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "print(f'Only other videos: \\t \\t Real: {r1:0.3f} Fake: {f1:0.3f}')\n",
    "\n",
    "print(f'3min Similar: \\t \\t Real: {r2:0.3f} Fake: {f2:0.3f}')\n",
    "\n",
    "plt.plot([0] + list(r_f3[:, 0]), [r1*100] + list(r_f3[:, 1]*100), label='real')\n",
    "plt.plot([0] + list(r_f3[:, 0]), [f1*100] + list(r_f3[:, 2]*100), label='fake')\n",
    "plt.xlabel('Time (Sec)')\n",
    "plt.ylabel('Acc')\n",
    "plt.grid(b=True)\n",
    "plt.legend()\n",
    "plt.title('T of Similar Vid')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot([0] + list(r_f4[:, 0]), [r1*100] + list(r_f4[:, 1]*100), label='real')\n",
    "plt.plot([0] + list(r_f4[:, 0]), [f1*100] + list(r_f4[:, 2]*100), label='fake')\n",
    "plt.xlabel('Time (Sec)')\n",
    "plt.ylabel('Acc')\n",
    "plt.grid(b=True)\n",
    "plt.legend()\n",
    "plt.title('Other + T of Similar Vid')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = [25, 50, 75, 100]\n",
    "y = [86.5, 91.7, 94.7, 95.9]\n",
    "\n",
    "x_nm = [1, 25]\n",
    "y_nm = [43.1, 50.44]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.plot(x, y, label='with metric')\n",
    "plt.plot(x_nm, y_nm, label='no metric')\n",
    "\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Recall@1')\n",
    "plt.grid(b=True)\n",
    "plt.title('voxceleb recall')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performance of diff length metric learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_one_time(N):\n",
    "    \n",
    "    vgg_repo_metric = get_train_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                    'frames':100, 'steps':5, 'N_comp':512})\n",
    "    fab_repo_metric = get_train_repo({'istrain':True, 'bsfldr':f'/data/home/shruti/voxceleb/fabnet_metric{N}/', \n",
    "                                    'frames':1, 'steps':1, 'N_comp':-1})\n",
    "\n",
    "    save_results(vgg_repo_metric, fab_repo_metric, \n",
    "                 ['bo','bs','dt','ew','hc','jb'], \n",
    "                 'real', 10, \n",
    "                 f'result_csv/ldr_real_{N}.csv', 0, 1, parallel=True)\n",
    "    save_results(vgg_repo_metric, fab_repo_metric, \n",
    "                 ['bo','bs','dt','ew','hc','jb'], \n",
    "                 'fake', 10, \n",
    "                 f'result_csv/ldr_fake_{N}.csv', 0, 1, parallel=True)\n",
    "\n",
    "    save_results(vgg_repo_metric, fab_repo_metric, \n",
    "                 ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                 'real', -1, \n",
    "                 f'result_csv/FF_real_{N}.csv', 0.5, 1, parallel=True)\n",
    "    save_results(vgg_repo_metric, fab_repo_metric, \n",
    "                 ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "                 'fake', -1, \n",
    "                 f'result_csv/FF_fake_{N}.csv', 0.5, 1, parallel=True)\n",
    "\n",
    "    save_results(vgg_repo_metric, fab_repo_metric, \n",
    "                 ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                 'real', -1, \n",
    "                 f'result_csv/GG_real_{N}.csv', 0, 1, parallel=True)\n",
    "    save_results(vgg_repo_metric, fab_repo_metric, \n",
    "                 ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "                 'fake', -1, \n",
    "                 f'result_csv/GG_fake_{N}.csv', 0, 1, parallel=True)\n",
    "\n",
    "    save_results(vgg_repo_metric, fab_repo_metric, \n",
    "                 ['jen_l'], \n",
    "                 'real', -1, \n",
    "                 f'result_csv/SJ_real_{N}.csv', 0, 1, parallel=True)\n",
    "    save_results(vgg_repo_metric, fab_repo_metric, \n",
    "                 ['steve_b'], \n",
    "                 'fake', -1, \n",
    "                 f'result_csv/SJ_fake_{N}.csv', 0, 1, parallel=True)\n",
    "\n",
    "    real_df = pd.read_csv(f'result_csv/ldr_real_{N}.csv')\n",
    "    print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "    fake_df = pd.read_csv(f'result_csv/ldr_fake_{N}.csv')\n",
    "    print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))\n",
    "\n",
    "    real_df = pd.read_csv(f'result_csv/GG_real_{N}.csv')\n",
    "    print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "    fake_df = pd.read_csv(f'result_csv/GG_fake_{N}.csv')\n",
    "    print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))\n",
    "\n",
    "    real_df = pd.read_csv(f'result_csv/FF_real_{N}.csv')\n",
    "    print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "    fake_df = pd.read_csv(f'result_csv/FF_fake_{N}.csv')\n",
    "    print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))\n",
    "\n",
    "    real_df = pd.read_csv(f'result_csv/SJ_real_{N}.csv')\n",
    "    print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "    fake_df = pd.read_csv(f'result_csv/SJ_fake_{N}.csv')\n",
    "    print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_one_time(25)\n",
    "run_one_time(50)\n",
    "run_one_time(75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test face forensics on these videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
