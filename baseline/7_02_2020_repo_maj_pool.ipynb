{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from repo import *\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the file names\n",
    "train_files, test_files = train_test_all_ids('/data/home/shruti/voxceleb/vgg/leaders/')\n",
    "all_lbls = list(train_files.keys())\n",
    "all_lbls.sort()\n",
    "all_lbls = np.array(all_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo with leaders + ff original + imposters + Google\n",
    "def get_train_repo(params):\n",
    "    \n",
    "    out_repo = Repo_maj_pool(params['bsfldr'], params['frames'], params['steps'], np.mean, 5000)\n",
    "    out_repo.add_ids({f: train_files[f] for f in ['bo','br','bs','cb','dt','ew','hc','jb','kh', 'pb',\n",
    "                                                  'bo_imposter','bs_imposter','ew_imposter','dt_imposter',\n",
    "                                                   'hc_imposter', 'jb_imposter']}, 0, 1)\n",
    "    out_repo.add_ids({'FF_{0:03d}'.format(f): train_files['FF_{0:03d}'.format(f)] for f in range(1000)}, 0, 0.5)\n",
    "    out_repo.add_ids({'GG_{0:02d}'.format(f+1): train_files['GG_{0:02d}'.format(f+1)] for f in range(28)}, 0, 1)\n",
    "    out_repo.add_ids({'steve_b': train_files['steve_b']}, 0, 1)\n",
    "    out_repo.add_ids({'jen_l': train_files['jen_l']}, 0, 1)\n",
    "    \n",
    "    out_repo.build_repo(params['N_comp'])\n",
    "    \n",
    "    return out_repo\n",
    "\n",
    "\n",
    "def save_results(vgg_repo, fab_repo, test_ids, r_or_f, N_f, out_file, n1, n2, parallel=False):\n",
    "        \n",
    "    # number of files per id\n",
    "    test_dict = {}\n",
    "    for ids in test_ids:\n",
    "        cur_test_files = test_files[r_or_f][ids]\n",
    "        if N_f>0 and len(cur_test_files)>N_f:\n",
    "            test_dict[ids] = cur_test_files[:N_f].copy()\n",
    "        else:\n",
    "            test_dict[ids] = cur_test_files.copy()\n",
    "            \n",
    "    vgg_result = vgg_repo.dist_using_dict(test_dict, n1, n2, parallel=parallel, dist='cosine')\n",
    "    vgg_result['RealFake'] = r_or_f\n",
    "    fab_result = fab_repo.dist_using_dict(test_dict, n1, n2, parallel=parallel, dist='cosine')\n",
    "    fab_result['RealFake'] = r_or_f\n",
    "    full_df = vgg_result.set_index('fileName').join(fab_result.set_index('fileName'), \n",
    "                                                 how='inner', lsuffix='_vgg', rsuffix='_fab')\n",
    "    full_df = full_df[['predLabel_vgg', 'actualLabel_vgg', 'RealFake_vgg', 'predLabel_fab']].copy()\n",
    "    \n",
    "    full_df.to_csv(out_file)\n",
    "    full_df = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG pool + Fabnet Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels 1046\n",
      "pca components: 256, explained variance 0.9931591374128844\n",
      "Build repo time: 125.959\n",
      "Number of labels 1046\n",
      "Build repo time: 1.848\n"
     ]
    }
   ],
   "source": [
    "vgg_repo = get_train_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':100, 'steps':5, 'N_comp':256})\n",
    "\n",
    "fab_repo = get_train_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet/leaders/', \n",
    "                                'frames':100, 'steps':5, 'N_comp':-1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the location of the base folder in the repo\n",
    "vgg_repo.bs_fldr = '/data/home/shruti/voxceleb/vgg/leaders/'\n",
    "fab_repo.bs_fldr = '/data/home/shruti/voxceleb/fabnet/leaders/'\n",
    "\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "             'real', -1, \n",
    "             'GG_real_vggfabpool.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "             'fake', -1, \n",
    "             'GG_fake_vggfabpool.csv', 0, 1, parallel=True)\n",
    "\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'real', 10, \n",
    "             'ldr_real_vggfabpool.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'fake', 10, \n",
    "             'ldr_fake_vggfabpool.csv', 0, 1, parallel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files['fake']['FF_001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=16)]: Done 2000 out of 2000 | elapsed: 21.2min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=16)]: Done 2000 out of 2000 | elapsed: 20.4min finished\n"
     ]
    }
   ],
   "source": [
    "save_results(vgg_repo, fab_repo, \n",
    "             ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "             'fake', -1, \n",
    "             'FF_fake_vggfabpool.csv', 0.5, 1, parallel=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(vgg_repo, fab_repo, \n",
    "             ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "             'real', -1, \n",
    "             'FF_real_vggfabpool.csv', 0.5, 1, parallel=True)\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['jen_l'], \n",
    "             'real', -1, \n",
    "             'SJ_real_vggfabpool.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo, fab_repo, \n",
    "             ['steve_b'], \n",
    "             'fake', -1, \n",
    "             'SJ_fake_vggfabpool.csv', 0, 1, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv('GG_real_vggfabpool.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('GG_fake_vggfabpool.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv('ldr_real_vggfabpool.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('ldr_fake_vggfabpool.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv('FF_real_vggfabpool.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('FF_fake_vggfabpool.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv('SJ_real_vggfabpool.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('SJ_fake_vggfabpool.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo of Leaders + Face Forensics Original + Imposter + Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vgg_repo_metric = get_train_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/vgg/leaders/', \n",
    "                                'frames':100, 'steps':5, 'N_comp':256})\n",
    "fab_repo_metric = get_train_repo({'istrain':True, 'bsfldr':'/data/home/shruti/voxceleb/fabnet_metric/', \n",
    "                                'frames':1, 'steps':1, 'N_comp':-1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg_repo_metric.bs_fldr = '/data/home/shruti/voxceleb/vgg/leaders/'\n",
    "fab_repo_metric.bs_fldr = '/data/home/shruti/voxceleb/fabnet_metric/'\n",
    "\n",
    "\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "             'real', -1, \n",
    "             'GG_real_100_vggpoolfabmet.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['GG_{0:02d}'.format(f+1) for f in range(28)], \n",
    "             'fake', -1, \n",
    "             'GG_fake_100_vggpoolfabmet.csv', 0, 1, parallel=True)\n",
    "\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'real', 10, \n",
    "             'ldr_real_100_vggpoolfabmet.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['bo','bs','dt','ew','hc','jb'], \n",
    "             'fake', 10, \n",
    "             'ldr_fake_100_vggpoolfabmet.csv', 0, 1, parallel=True)\n",
    "\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "             'real', -1, \n",
    "             'FF_real_100_vggpoolfabmet.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['FF_{0:03d}'.format(f) for f in range(1000)], \n",
    "             'fake', -1, \n",
    "             'FF_fake_100_vggpoolfabmet.csv', 0, 1, parallel=True)\n",
    "\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['jen_l'], \n",
    "             'real', -1, \n",
    "             'SJ_real_100_vggpoolfabmet.csv', 0, 1, parallel=True)\n",
    "save_results(vgg_repo_metric, fab_repo_metric, \n",
    "             ['steve_b'], \n",
    "             'fake', -1, \n",
    "             'SJ_fake_100_vggpoolfabmet.csv', 0, 1, parallel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "real_df = pd.read_csv('GG_real_100_vggpoolfabmet.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('GG_fake_100_vggpoolfabmet.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "real_df = pd.read_csv('ldr_real_100_vggpoolfabmet.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('ldr_fake_100_vggpoolfabmet.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "real_df = pd.read_csv('FF_real_100_vggpoolfabmet.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('FF_fake_100_vggpoolfabmet.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv('SJ_real_100_vggpoolfabmet.csv')\n",
    "print(len(np.argwhere(np.array(real_df['predLabel_vgg'])==np.array(real_df['predLabel_fab'])).ravel())/len(real_df))\n",
    "\n",
    "fake_df = pd.read_csv('SJ_fake_100_vggpoolfabmet.csv')\n",
    "print(len(np.argwhere(np.array(fake_df['predLabel_vgg'])==np.array(fake_df['predLabel_fab'])).ravel())/len(fake_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
